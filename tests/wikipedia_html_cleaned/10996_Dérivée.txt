En mathématiques, la dérivée d'une fonction d'une variable réelle mesure l'ampleur du changement de la valeur de la fonction (valeur de sortie) par rapport à un petit changement de son argument (valeur d'entrée). Les calculs de dérivées sont un outil fondamental du calcul infinitésimal. Par exemple, la dérivée de la position d'un objet en mouvement par rapport au temps est la vitesse (instantanée) de l'objet.
La dérivée d'une fonction
f
{\displaystyle f}
est une fonction qui, à tout nombre pour lequel
f
{\displaystyle f}
admet un nombre dérivé, associe ce nombre dérivé. La dérivée en un point d'une fonction de plusieurs variables réelles, ou à valeurs vectorielles, est plus couramment appelée différentielle de la fonction en ce point et n'est pas traitée ici.
La dérivée d'une fonction
f
{\displaystyle f}
en
x
{\displaystyle x}
est usuellement notée
f
x
{\displaystyle f'(x)}
ou
d
f
d
x
x
{\displaystyle {\frac {{\mathrm {d} }f}{{\mathrm {d} }x}}(x)}
On utilise aussi des notations spécifiques, en particulier en physique, pour désigner la dérivée par rapport au temps qui s'écrit avec un point surmontant la lettre (
f
{\displaystyle {\dot {f}}}
), la dérivée seconde s'écrivant alors grâce à un tréma surmontant la lettre. Cette notation est appelée « notation de Newton ». On utilise dans le même esprit les notations prime (
f
{\displaystyle f'}
) et seconde (
f
{\displaystyle f''}
) pour noter les dérivées par rapport à l'espace.
En analyse, le nombre dérivé en un « point » (réel)
x
{\displaystyle x}
d'une fonction
f
{\displaystyle f}
à variable et valeurs réelles est la pente de la tangente au graphe de
f
{\displaystyle f}
au point
x
f
x
{\displaystyle \left(x,f(x)\right)}
C'est le coefficient directeur de l'approximation affine de
f
{\displaystyle f}
en
x
{\displaystyle x}
 ; ce nombre n'est donc défini que si cette tangente — ou cette approximation — existe. La notion de dérivée est une notion fondamentale en analyse permettant d'étudier les variations d'une fonction, de construire des tangentes à une courbe et de résoudre des problèmes d'optimisation.
En sciences, lorsqu'une grandeur est fonction du temps, la dérivée de cette grandeur donne la vitesse instantanée de variation de cette grandeur, et la dérivée de la dérivée donne l'accélération. Par exemple, la vitesse instantanée d'un mobile est la valeur à cet instant de la dérivée de sa position par rapport au temps, et son accélération est la valeur à cet instant de la dérivée, par rapport au temps, de sa vitesse.
On généralise la notion de dérivée en étendant celle-ci au champ complexe et on parle alors de dérivée complexe. Pour une fonction de plusieurs variables réelles, on parle de la dérivée partielle par rapport à l'une de ses variables.
Il existe aussi une définition purement algébrique de la dérivée. On en trouve un exemple dans l'article polynôme formel.

Histoire :

Sa création est liée à une polémique entre deux mathématiciens : Isaac Newton et Gottfried Wilhelm Leibniz. Néanmoins, on retrouve chez des mathématiciens plus anciens les prémices de ce type de calcul : Pierre de Fermat et Isaac Barrow notamment. L'histoire du calcul infinitésimal remonte même à l'Antiquité, avec Archimède.
La notion de nombre dérivé a vu le jour au XVIIe siècle dans les écrits de Leibniz et ceux de Newton, qui le nomme fluxion et qui le définit comme « le quotient ultime de deux accroissements évanescents ». C'est à Lagrange (fin du XVIIIe siècle) que l'on doit la notation
f
x
{\displaystyle f'(x)}
aujourd'hui usuelle, pour désigner le nombre dérivé de
f
{\displaystyle f}
en
x
{\displaystyle x}
C'est aussi à lui qu'on doit le nom de « dérivée » pour désigner ce concept mathématique.

Approche à partir de la pente de la tangente :

Pour approcher cette notion de manière graphique, commençons par nous donner une courbe représentative d'une fonction continue dans un repère cartésien, c'est-à-dire tracée d'un seul trait de crayon, et bien « lisse » ; on dira là que la fonction associée est dérivable.
Quel que soit le point que l'on choisit sur la courbe, on pourra alors tracer ce qu'on appelle une tangente, c'est-à-dire une droite qui épouse localement la direction de cette courbe. Si l'on trace la courbe et sa tangente et que l'on s'approche en zoomant suffisamment, on aura de plus en plus de mal à distinguer la courbe de sa tangente. Si la courbe « monte » (c'est-à-dire si la fonction associée est croissante), la tangente sera également montante ; inversement, si la fonction est décroissante, la tangente sera descendante.
Si on se donne une abscisse
x
0
{\displaystyle x_{0}}
pour laquelle la fonction
f
{\displaystyle f}
est dérivable, on appelle nombre dérivé de
f
{\displaystyle f}
en
x
0
{\displaystyle x_{0}}
le coefficient directeur de la tangente à la courbe au point d'abscisse
x
0
{\displaystyle x_{0}}
Ce réel donne de précieuses informations sur le comportement local d'une fonction : c'est la mesure algébrique de la vitesse à laquelle cette fonction change lorsque sa variable change.
Ainsi, si le nombre dérivé d'une fonction est positif sur un intervalle, cette fonction sera croissante sur ce même intervalle. Inversement, s'il est négatif, elle sera décroissante. Lorsque le nombre dérivé est nul en un point, la courbe admet une tangente horizontale en ce point (pour plus de détails, voir Fonction monotone#Monotonie et signe de la dérivée). Si de plus le nombre dérivé change de signe en ce point, alors la fonction admet un extremum local (minimum ou maximum) ; sinon, on obtient ce qu'on appelle un point d'inflexion et ainsi la courbe change de concavité.

Définition formelle :

Soit
f
{\displaystyle f}
une fonction réelle à valeurs réelles définie sur une réunion quelconque d'intervalles non triviaux (c'est-à-dire non vides et non réduits à un point), et
x
0
{\displaystyle x_{0}}
appartenant à l'intérieur de l'ensemble de définition
D
f
{\displaystyle {\mathcal {D}}_{f}}
Pour tout
h
R
{\displaystyle h\in \mathbb {R} ^
tel que
x
0
x
0
h
D
f
{\displaystyle [x_{0},x_{0}+h]\subset {\mathcal {D}}_{f}}
on appelle taux d'accroissement de
f
{\displaystyle f}
en
x
0
{\displaystyle x_{0}}
et avec un pas de
h
{\displaystyle h}

la quantité :

Il s'agit du coefficient directeur de la droite reliant les points de coordonnées
x
0
f
x
0
{\displaystyle \left(x_{0},f(x_{0})\right)}
et
x
0
h
f
x
0
h
{\displaystyle \left(x_{0}+h,f(x_{0}+h)\right)}
Si
t
x
0
h
{\displaystyle t_{x_{0}}(h)}
admet une limite finie lorsque
h
{\displaystyle h}
tend vers 0, on dit que
f
{\displaystyle f}
est dérivable en
x
0
{\displaystyle x_{0}}
auquel cas le nombre dérivé de
f
{\displaystyle f}
en
x
0
{\displaystyle x_{0}}

est égal à la limite de ce taux d'accroissement. On note alors :

ou, de manière équivalente :
Une fonction pour laquelle le taux d'accroissement en un point admet une limite finie (qui est le nombre dérivé) est dite dérivable en ce point.

Ce calcul de limite revient graphiquement à rechercher la pente de la tangente à la courbe en ce point. Ainsi, le nombre dérivé d'une fonction en un point, s'il existe, est égal à la pente de la tangente à la courbe représentative de la fonction en ce point :

La dérivation peut aussi être définie pour des fonctions d'une variable réelle à valeurs dans d'autres ensembles que
R
{\displaystyle \mathbb {R} }
Par exemple, une fonction
f
{\displaystyle f}
d'une variable réelle, à valeurs dans
R
n
{\displaystyle \mathbb {R} ^{n}}
est dérivable en
x
0
{\displaystyle x_{0}}
si et seulement si toutes ses coordonnées sont dérivables en
x
0
{\displaystyle x_{0}}
 ; et sa dérivée est la fonction dont les coordonnées sont les dérivées des coordonnées de
f
{\displaystyle f}
C'est un cas particulier de fonctions d'une variable vectorielle et à valeurs dans un espace vectoriel normé ou métrique.

Dérivabilité et lien avec la continuité :

Typiquement, une fonction est dérivable si elle ne présente pas « d'aspérité », de rupture de pente ni de partie « verticale ».
Une fonction qui n'est pas continue en un point n'y est pas dérivable. Prenons l'exemple d'une fonction qui fait un saut. On ne peut pas définir de tangente, la limite du taux de variation est infinie (la pente de la courbe est verticale). C'est le cas par exemple de la fonction signe
sgn
x
{\displaystyle \operatorname {sgn}(x)}

en 0 :

* à gauche de 0, i.e.
x
0
{\displaystyle x<0}
sgn
x
1
{\displaystyle \operatorname {sgn}(x)=-1}

* en 0 :

sgn
0
0
{\displaystyle \operatorname {sgn}(0)=0}
* à droite de 0, i.e.
x
0
{\displaystyle x>0}
sgn
x
1
{\displaystyle \operatorname {sgn}(x)=+1}
le taux de variation pour une largeur
h
{\displaystyle h}
vaut donc
et tend vers
{\displaystyle +\infty }
quand
h
{\displaystyle h}
tend vers 0. Par contre, on peut définir une dérivée à gauche — dérivée partout nulle (tangente horizontale) sur
0
{\displaystyle ]-\infty ,0
— et une dérivée à droite — dérivée également nulle sur
0
{\displaystyle ]0,+\infty
Si une fonction est dérivable en un point alors elle est continue en ce point, mais la réciproque est fausse.
Par exemple : la fonction valeur absolue
x
x
{\displaystyle x\mapsto |x|}

est continue mais n'est pas dérivable en 0 :

* à gauche de 0, i.e.
x
0
{\displaystyle x<0}
la pente vaut
1
{\displaystyle -1}
* à droite de 0, i.e.
x
0
{\displaystyle x>0}
la pente vaut
1
{\displaystyle +1}
Il y a une tangente à gauche et une tangente à droite différentes, la pente en 0 n'est pas définie ; le taux de variation n'a pas de limite définie. C'est le cas général pour les courbes présentant un point anguleux.
Il en est de même de la fonction racine cubique, qui a une tangente verticale en
x
0
{\displaystyle x=0}
 : le taux de variation a une limite infinie.
De plus, une fonction continue en un ensemble ne garantit pas que la fonction soit dérivable en cet ensemble (ouvert), comme contre-exemple la fonction de Weierstrass est continue sur
R
{\displaystyle \mathbb {R} }
mais dérivable nulle part.

Fonction dérivée :

La dérivabilité est a priori une notion locale (dérivabilité en un point), mais à toute fonction
f
D
f
R
{\displaystyle f:{\mathcal {D}}_{f}\to \mathbb {R} }
on peut associer sa fonction dérivée
f
{\displaystyle f'}
(prononcée « 
f
{\displaystyle f}
prime »), donnée par
où
D
f
{\displaystyle {\mathcal {D}}_{f'}}
est le domaine de dérivabilité de
f
{\displaystyle f}
(le sous-ensemble de
D
f
{\displaystyle {\mathcal {D}}_{f}}
constitué des points en lesquels
f
{\displaystyle f}
est dérivable).
Les fonctions dérivées sont utilisées notamment dans l'étude des fonctions réelles et de leurs variations.
La seule fonction (à une constante multiplicative près) égale à sa dérivée — c'est-à-dire solution de l'équation différentielle
f
f
{\displaystyle f'=f}
— est la fonction exponentielle de base
e
{\displaystyle \mathrm {e} }
Certains ouvrages prennent cette propriété, avec la condition
f
0
1
{\displaystyle f(0)=1}
comme définition de l'exponentielle.

Notations :

Il existe différentes notations pour exprimer la valeur de la dérivée d'une fonction
f
{\displaystyle f}
en un point
a
{\displaystyle a}

On distingue :

* la notation de Lagrange :
f
a
{\displaystyle f'\left(a\right)}

* la notation de Leibniz :

d
f
d
x
a
{\displaystyle {\frac {{\mathrm {d} }f}{{\mathrm {d} }x}}(a)}
ou
d
f
d
x
x
a
{\displaystyle \left.{\frac {{\mathrm {d} }f}{{\mathrm {d} }x}}\right|_{x=a}}
En physique, on note parfois
d
f
a
d
x
{\displaystyle {\frac {{\mathrm {d} }\left(f(a)\right)}{{\mathrm {d} }x}}}
Cette dernière notation n'est pas rigoureuse car
f
a
{\displaystyle f(a)}
est un nombre constant, qui peut être vu comme une fonction constante
g
X
g
X
f
a
{\displaystyle g:X\mapsto g(X)=f(a)}
 : rigoureusement, on a donc
d
f
a
d
x
0
{\displaystyle {\frac {{\mathrm {d} }\left(f(a)\right)}{{\mathrm {d} }x}}=0}

* la notation de Newton :

f
a
{\displaystyle {\dot {f}}(a)}
qui est plutôt utilisée en physique pour désigner une dérivée par rapport au temps (on parle alors de calcul des fluxions) ;

* la notation d'Euler :

D
x
f
a
{\displaystyle D_{x}f(a)}
Ces notations permettent également d'écrire des dérivées itérées, cela se fait en multipliant le prime ou le point dans la notation (par exemple une dérivée seconde peut s'écrire
f
a
{\displaystyle f''(a)}
ou
f
a
{\displaystyle {\ddot {f}}(a)}

Dérivées usuelles et règles de dérivation :

f
{\displaystyle f'}
peut souvent se calculer directement à partir d'une expression de
f
{\displaystyle f}

Dérivation numérique :

Dans le cas d'une courbe expérimentale, on ne possède pas de fonction explicite pour la décrire, mais une série de valeurs
x
i
y
i
{\displaystyle (x_{i},y_{i})}
On a donc recours à une dérivation numérique, qui consiste simplement à approcher la valeur de la dérivée en un point
i
{\displaystyle i}

par le taux de variation entre les points précédent et suivant :

Graphiquement, cela revient à remplacer la tangente par la corde. Ceci peut se justifier par le théorème des accroissements finis : on sait qu'il existe un point de l'intervalle
x
i
1
x
i
1
{\displaystyle \left[x_{i-1},x_{i+1}\right]}
pour lequel la dérivée est la pente de la corde, et si l'intervalle est petit, alors ce point est proche du milieu
x
i
{\displaystyle x_{i}}
 . Cette méthode est automatisable sur les calculatrices programmables et les ordinateurs.
Il faut cependant se poser la question de la précision des résultats. Une mise en informatique « naïve » de la méthode de calcul peut mener à des résultats de précision médiocre dans certains cas.
Dans un ordinateur, la précision des nombres est limitée par le mode de représentation. Si l'on utilise la double précision selon la norme IEEE 754, les nombres ont environ 16 chiffres significatifs. On a donc une précision relative de l'ordre de 10−16 (2−52 exactement). Notons
r
{\displaystyle r}
cette valeur. Les calculatrices de poche admettent typiquement 10 chiffres significatifs, soit
r
{\displaystyle r}
= 10−10.
Supposons que la différence
y
i
1
y
i
1
{\displaystyle y_{i+1}-y_{i-1}}
soit inférieure à
r
{\displaystyle r}
alors le calculateur fera une erreur grossière sur le calcul et le résultat sera médiocre ; voire, si la différence est très faible, il ne « verra pas » de différence entre les deux valeurs, et le résultat sera 0. Si par exemple on veut avoir la dérivée autour de 2 de la fonction
f
x
x
2
{\displaystyle f(x)=x^{2}}

en prenant un écart de 10−13 entre les points :

On voit que la différence entre les nombres, 8 × 10−13, est proche de
r
{\displaystyle r}
On va donc avoir une erreur d'arrondi. De fait, le calcul nous donne sur un ordinateur
alors que le résultat exact est
soit une erreur de 0,3 %. Sur une calculatrice, le résultat est
f
2
{\displaystyle f'(2)}
≈ 0…
Le point critique est le choix de l'écart
h
{\displaystyle h}
entre les valeurs de
x
{\displaystyle x}
Une valeur de l'ordre de
r
{\displaystyle {\sqrt {r}}}
convient dans de nombreux cas. Il nous manque encore quelques éléments pour cette étude ; le problème est abordé dans la section Précision de la dérivée numérique ci-dessous.

Donc :

* pour un ordinateur calculant en double précision, on peut prendre un écart de 10−8 entre les points ;
* pour une calculatrice avec 10 chiffres significatifs, on peut prendre un écart de 10−5 entre les points.

Précision de la dérivée numérique :

On peut approcher une fonction
f
{\displaystyle f}

de classe C2 par un polynôme appelé développement limité :

Il en vient une approximation de la dérivée à l'ordre 2 :
Ce faisant, on commet une erreur de troncature du second ordre
Par ailleurs, l'ordinateur commet une erreur d'arrondi : la précision relative étant
r
{\displaystyle r}
la précision absolue sur
f
x
{\displaystyle f(x)}
est
f
x
r
{\displaystyle |f(x)|r}
et donc l'erreur induite sur la dérivée
L'erreur totale vaut donc
Cette fonction est convexe, et admet un minimum en
Cela dépend donc du rapport entre la valeur de
f
{\displaystyle f}
et la courbure
f
{\displaystyle f''}
Pour les zones où la fonction
f
{\displaystyle f}
est « modérée » — c'est-à-dire que
f
f
{\displaystyle f/f''}
est de l'ordre de l'unité —, on peut retenir
L'erreur commise sur le premier terme (« erreur de méthode ») est en fait bien plus petite, puisque la méthode du paragraphe précédent revient à approximer
f
x
{\displaystyle f'(x)}
par
f
x
h
f
x
h
2
h
{\displaystyle {\frac {f(x+h)-f(x-h)}{2h}}}
 ; le même développement limité (pris cette fois à l'ordre 3) montre qu'on commet alors une erreur de l'ordre de
f
x
6
h
2
{\displaystyle {f'''(x) \over 6}h^{2}}
Il en résulte que le principal défaut de ces méthodes d'approximation numérique vient des erreurs d'arrondi.
Des formules plus complexes donnent de meilleures approximations ; voir à ce sujet l’article Dérivation numérique.

Dérivation graphique :

On peut également effectuer une dérivation graphique, sans utiliser de calcul. On approche les tangentes par les cordes comme pour la méthode numérique. Puis, on tire des parallèles à ces droites passant par un point nommé pôle P. On considère l'intersection de ces droites avec la verticale passant par O, le segment [OP] étant horizontal. La hauteur
v
i
{\displaystyle v_{i}}
des segments ainsi délimités est proportionnelle à la pente
a
i
{\displaystyle a_{i}}
on peut donc reporter cette hauteur sur le graphique et obtenir une approximation de la courbe dérivée. L'échelle de l'axe des
y
{\displaystyle y}
est donc de OP:1.

Dérivée d'ordre n :

La dérivée seconde, notée
f
{\displaystyle f''}
est la dérivée de la dérivée de
f
{\displaystyle f}

lorsqu'elle existe :

et la dérivée troisième est la dérivée de la dérivée seconde, lorsqu'elle existe :
De manière générale, on définit la dérivée d'ordre
n
{\displaystyle n}
pour une fonction
n
{\displaystyle n}

fois dérivable par récurrence :

d
n
f
d
x
n
{\displaystyle {\frac {{\mathrm {d} }^{n}f}{{\mathrm {d} }x^{n}}}}
est également notée
f
n
{\displaystyle f^{(n)}}

Formule de Leibniz :

Si
f
{\displaystyle f}
et
g
{\displaystyle g}
sont des fonctions
n
{\displaystyle n}

fois dérivables, alors, par application de la règle du produit :

En particulier pour
n
2
{\displaystyle n=2}
On notera l'analogie avec la formule du binôme de Newton. Cela provient de la bilinéarité de l'opérateur de dérivation d'un produit.

Propriétés des fonctions dérivables :

Théorème de Rolle :
Soient
a
{\displaystyle a}
et
b
{\displaystyle b}
deux réels tels que
a
b
{\displaystyle a<b}
Si
f
{\displaystyle f}
est continue sur
a
b
{\displaystyle [a,b]}
dérivable sur
a
b
{\displaystyle ]a,b
et si
f
a
f
b
{\displaystyle f(a)=f(b)}
alors il existe (au moins) un réel
c
{\displaystyle c}
dans
a
b
{\displaystyle ]a,b

tel que :

Théorème des accroissements finis :
En particulier, si
f
a
f
b
{\displaystyle f(a)=f(b)}
on retrouve le théorème de Rolle, qui sert aussi à démontrer le résultat plus général (voir l'article détaillé), c'est pourquoi on le rencontre souvent sous le nom de lemme de Rolle.
Cette propriété est utilisée en cinématique pour déterminer une approximation du vecteur vitesse à partir d'un relevé de point.

Discontinuités :

Une partie
A
{\displaystyle A}
d'un intervalle réel
I
{\displaystyle I}
est l'ensemble des points de continuité de la dérivée d'une fonction dérivable de
I
{\displaystyle I}
dans
R
{\displaystyle \mathbb {R} }
si et seulement si
A
{\displaystyle A}
est un ensemble Gδ dense dans
I
{\displaystyle I}
L'ensemble des points de discontinuité d'une dérivée est donc un ensemble Fσ d'intérieur vide quelconque.

Théorème de Darboux :

Si
f
{\displaystyle f}
est dérivable, sa fonction dérivée
f
{\displaystyle f'}
n'est donc pas nécessairement continue. Cependant,
f
{\displaystyle f'}

possède la propriété des valeurs intermédiaires. Ceci constitue le théorème de Darboux, qui peut se formuler de deux façons équivalentes :

Dérivées de fonctions liées :
Beaucoup de problèmes font intervenir plusieurs variables qui sont liées entre elles et qui varient en fonction du temps.
La variation de l'une de ces variables donnera une variation correspondante des autres variables.
Le lien entre ces variations dépendra des relations qui existent entre les variables.

Analyse d'une fonction dérivée :

En trouvant les valeurs de
x
{\displaystyle x}
pour lesquelles la dérivée vaut 0 ou n'existe pas, on trouve les nombres critiques de la fonction. Les nombres critiques de
f
{\displaystyle f}
permettent de trouver implicitement ses maxima et ses minima. En effectuant le test de la dérivée première, on construit un tableau de variation ; si le signe de la fonction dérivée passe du plus au moins devant un nombre critique, on a un maximum et si le signe de la fonction dérivée passe du moins au plus devant le nombre critique, on a un minimum.
De plus, lorsque le signe de la dérivée première est positif, la fonction est croissante ; s'il est négatif, elle est décroissante. On ne conclut rien, si au point critique la fonction dérivée ne change pas de signe. En dérivant la dérivée première, on a la dérivée seconde. En effectuant le test de la dérivée seconde, on trouve les nombres critiques de la dérivée première pour les placer dans le même tableau ; lorsqu'on observe un changement de signe de la dérivée seconde devant ce ou ces nombres critiques, on dit qu'on a un (ou des) point(s) d'inflexion. Les points d'inflexion marquent un changement de la concavité de la fonction. Un signe positif de la dérivée seconde signifie que la fonction est convexe et un signe négatif de la dérivée seconde signifie que la fonction est concave. Connaissant les changements de concavité et les extrema de la fonction, on peut alors tracer une esquisse de sa représentation graphique.

Dérivée et optimisation :

Méthode pour optimiser un rendement à l'aide du calcul différentiel :
* Mathématisation
Définitions et dessin : on définit les variables inconnues et on les représente sur un schéma.
Écrire la fonction objectif à deux variables et préciser si on recherche un maximum ou un minimum dans la situation donnée.
Trouver la relation entre les deux variables.
Écrire la fonction objectif à une variable et préciser le domaine de la fonction.
* Définitions et dessin : on définit les variables inconnues et on les représente sur un schéma.
* Écrire la fonction objectif à deux variables et préciser si on recherche un maximum ou un minimum dans la situation donnée.
* Trouver la relation entre les deux variables.
* Écrire la fonction objectif à une variable et préciser le domaine de la fonction.
* Analyse
Dériver la fonction pour obtenir la dérivée première.
Trouver les nombres critiques de la fonction, où la dérivée première vaut zéro ou n'existe pas dans les intervalles du domaine.
Effectuer le test de la dérivée première ou le test de la dérivée seconde pour déterminer le maximum ou le minimum recherché de la situation.
* Dériver la fonction pour obtenir la dérivée première.
* Trouver les nombres critiques de la fonction, où la dérivée première vaut zéro ou n'existe pas dans les intervalles du domaine.
* Effectuer le test de la dérivée première ou le test de la dérivée seconde pour déterminer le maximum ou le minimum recherché de la situation.
* On formule la réponse de façon concise par rapport à la question.

Dérivée algébrique :

Les algébristes donnent un sens un peu différent au terme dérivée. Ils l'appliquent à une structure
B
{\displaystyle B}
appelée A-algèbre associative unitaire et commutative. Une application
D
{\displaystyle D}
de
B
{\displaystyle B}
dans
B
{\displaystyle B}

est appelée une dérivation si :

* l'application
D
{\displaystyle D}
est A-linéaire ;
* b
1
{\displaystyle b_{1}}
et
b
2
{\displaystyle b_{2}}
étant deux éléments de
B
{\displaystyle B}
la dérivée de
b
1
b
2
{\displaystyle b_{1}\cdot b_{2}}
est égale à la somme du produit de la dérivée de
b
1
{\displaystyle b_{1}}
et de
b
2
{\displaystyle b_{2}}
et du produit de
b
1
{\displaystyle b_{1}}
avec la dérivée de
b
2
{\displaystyle b_{2}}
D
b
1
b
2
D
b
1
b
2
b
1
D
b
2
{\displaystyle D(b_{1}\cdot b_{2})=D(b_{1})\cdot b_{2}+b_{1}\cdot D(b_{2})}
(en particulier, la dérivée de l'élément
1
B
{\displaystyle 1_{B}}
neutre de
B
{\displaystyle B}
pour la multiplication est nulle).
Un exemple de dérivation définie de cette manière est donné dans l'article polynôme formel.

Dérivée fractionnaire :

Une autre généralisation part de la notion de dérivée n-ème pour construire, à l'aide de la transformation de Laplace, une nouvelle fonction, la dérivée t-ème, où t est un réel quelconque, et qui coïncide avec la dérivée itérée si t est entier et si la fonction de départ est suffisamment régulière.

Dérivation en tant qu'application linéaire :

La dérivation est une application linéaire, de l'espace vectoriel des fonctions dérivables sur un intervalle ouvert non vide
I
{\displaystyle I}
de
R
{\displaystyle \mathbb {R} }
et à valeurs réelles, vers celui des fonctions quelconques de
I
{\displaystyle I}
dans
R
{\displaystyle \mathbb {R} }
Son noyau est constitué des fonctions constantes et plus généralement, tout réel
λ
{\displaystyle \lambda }
est valeur propre, de sous-espace propre associé la droite de toutes les fonctions de la forme
x
a
e
λ
x
{\displaystyle x\mapsto a\mathrm {e} ^{\lambda x}}
avec
a
R
{\displaystyle a\in \mathbb {R} }
La dérivation en tant qu'endomorphisme de l'espace
E
C
I
C
{\displaystyle E={\mathcal {C}}^{\infty }(I,\mathbb {C} )}
n'admet pas de racine carrée, c'est-à-dire que si l'on note
D
E
E
{\displaystyle D:E\to E}
l'opérateur de dérivation, alors il n'existe pas d'application linéaire
T
E
E
{\displaystyle T:E\to E}
telle que
T
T
D
{\displaystyle T\circ T=D}
