Les [[constante d'équilibre|constantes d'équilibre]] sont évaluées pour quantifier les [[équilibre chimique|équilibres chimiques]] à partir de mesures de [[concentration (chimie)|concentrations]], directes ou indirectes, et mettant en œuvre des techniques numériques.

Cet article se limite aux équilibres en [[solution (chimie)|solutions]] entre [[soluté]]s pour lesquels [[activité chimique|l'activité chimique]] est mesurée par la [[concentration molaire]] en mol L<sup>−1</sup>. Destiné aux praticiens spécialisés ainsi qu'aux apprentis ayant une appréciation de base des équilibres chimiques, cet article traite du sujet en profondeur jusqu'à permettre la programmation des techniques de détermination en se souciant de la rigueur statistique, et s'attarde à l'interprétation objective des résultats.

== Introduction ==

Un [[équilibre chimique]] peut s'écrire en général
:<math>aA+bB+...\rightleftharpoons pP+qQ+...</math>
où l'on distingue les réactifs <math>A</math>, <math>B,...</math>, à gauche de la double flèche, des produits <math>P</math>, <math>Q,...</math> à sa droite. On peut s'approcher de l'équilibre des deux directions, et cette distinction entre réactifs et produits n'est que conventionnelle. La double flèche indique un échange dynamique, plus ou moins rapide, entre réactifs et produits, et l'équilibre est atteint lorsque les [[concentration molaire|concentrations]] des espèces participantes deviennent constantes. Le rapport des produits des concentrations, habituellement représenté par <math>K</math> et appelé la constante d'équilibre, s'écrit conventionnellement avec les réactifs au dénominateur et produits au numérateur ainsi
:<math>K = \frac {[P]^p[Q]^q...}{[A]^a[B]^b...}</math> ,
Ce rapport sera alors constant à une [[température]] donnée, pourvu que le [[Fraction (mathématiques)|quotient]] des [[activité chimique|activités chimiques]] est constant, supposition qui sera valide à une [[force ionique]] élevée, faute de quoi ce seront les activités qu'il faudra évaluer. Il exprime la position de l'équilibre, plus ou moins favorable (<math>K>1</math>) ou défavorable (<math>K<1</math>), que l'on peut quantifier si l'on peut mesurer la concentration de l'une des espèces en équilibre, avec l'aide des quantités analytiques (concentrations, masses ou volumes) des [[Réactif (chimie)|réactifs]] mis en œuvre.

Plusieurs types de mesures sont possibles. Cet article touche les trois types principalement utilisés et leurs limitations. Plusieurs autres, plus rares, sont décrits dans l'œuvre classique de Rossotti et Rossotti<ref>{{Ouvrage|langue=en|co-auteurs=H. Rossotti|prénom1=F. J. C.|nom1=Rossotti|titre=The determination of stability constants|éditeur=[[McGraw-Hill Education|McGraw-Hill]]|année=1961}}</ref>.

Sauf s'il s'agit d'un système expérimental très simple, les rapports entre les constantes d'équilibre et les concentrations mesurées seront non linéaires. Avec un ordinateur rapide et un logiciel équipé, et ayant une quantité suffisante de mesures de concentration, la détermination d'un nombre indéfini de <math>K</math>, impliquant un nombre indéfini d'espèces en solution, se fait facilement et de manière statistiquement rigoureuse par solution numérique des rapports non linéaires qui décrivent un système d'équilibres enchevêtrés. Cette détermination suit alors le parcours d'une modélisation, avec trois étapes : l'articulation d'un modèle, sa numérisation et son affinement. Cet article détaille ces trois étapes et finit par proposer certains logiciels utiles.

== Mesures expérimentales ==

La détermination de constantes d'équilibre se fait depuis plusieurs décennies et les techniques utilisées ont beaucoup évolué et sont devenues de véritables spécialités. Ce résumé ne peut pas donner tous les détails nécessaires à l'acquisition de mesures valables, et le lecteur se reportera aux textes spécialisés pour ce faire.

=== Potentiométrie et pH-métrie ===

La concentration de certaines espèces peut être mesurée à l'aide d'[[électrode]]s spécialisées, telles que l'électrode de verre indicatrice du pH (pour mesurer [H<sup>+</sup>]) ou les électrodes sélectives (de verre ou à membrane) pour certains autres ions<ref>CRC Handbook of Ion Selective Electrodes, CRC Press, Boca Raton, FL, USA.</ref>. Ces électrodes devront être calibrées avec des [[solution (chimie)|solutions]] de référence à concentration fixe.

Pour les mesures de [[Potentiel hydrogène|pH]]<ref>{{article|langue=en|prénom=A. K.|nom=Covington|coauteurs=R. G. Bates and R. A. Durst|titre=Definition of pH Scales, Standard Reference Values, Measurement of pH and Related Terminology|journal=Pure Appl. Chem.|pages=531–542|date=1985}}</ref>, des solutions-tampons seront utilisées et les lectures du [[pH-mètre]] obéiront
:<math>pH = nF/RT (E^0-E)</math> ,
expression dérivée de l'[[équation de Nernst]], où <math>E^0</math> est le potentiel standard de l'électrode, <math>E</math> est la mesure potentiométrique, <math>n</math> est le nombre d'électrons impliqués (= 1), <math>F</math> est la [[constante de Faraday]], <math>R</math> est la constante de gaz idéal et <math>T</math> représente la [[température]] (en kelvin). Chaque unité de pH engendre une différence de potentiel d'environ {{unité|59|mV}} à 298 K. La [[Graphe de Gran|méthode de Gran]] peut, à l'aide d'une titration acide fort-base forte, servir d’[[Étalonnage (métrologie)|étalonnage]] et détecter la présence de carbonates dans un titrant à base d'[[hydroxyde]].

Pour toutes mesures potentio- ou pH-métriques, un étalonnage simple peut se faire à l'aide de l'équation de Nernst modifiée
:<math>E=a+b \log_{10} [A]</math>
où <math>A</math> représente l'espèce détectée par l'électrode. Au minimum deux mesures, depuis au moins deux concentrations de référence, suffisent pour établir les paramètres empiriques <math>a</math> et <math>b</math> permettant ainsi de convertir les potentiels en concentrations.

Le nombre de données doit égaler ou excéder le nombre de constantes d'équilibre à déterminer, ce qui est facile avec une titration.

==== Limitations ====
Des valeurs de constantes d'équilibre entre environ 10<sup>2</sup> et 10<sup>11</sup> peuvent être mesurées directement par potentiométrie à l'aide d'[[électrode]]s de [[verre]], grâce à la réponse [[logarithme|logarithmique]] de ces électrodes. La [[méthode par compétition]] peut étendre cette plage, mais l'[[équation de Nernst]] tient mal à très bas ou très haut [[Potentiel hydrogène|pH]].

=== Spectrométrie électronique ===

L'[[absorbance]] à une [[longueur d'onde]] dans la région visible ou de l'[[ultraviolet]] doit obéir la [[loi de Beer-Lambert]], où il existe un rapport linéaire entre la mesure et la concentration de l'espèce mesurée, soit
:<math>A^{\lambda}=\ell \sum_i {\epsilon^{\lambda}_i c_i}</math>
où <math>\ell</math> est la longueur du [[absorbance|chemin optique]], <math>\epsilon^{\lambda}_i</math> est l'[[absorptivité molaire]] (le coefficient d'extinction molaire) à chemin optique unitaire à la longueur d'onde <math>\lambda</math> de l' <math>i</math> <sup>ème</sup> espèce chromophore à concentration <math>c_i</math>. Cette formulation reconnaît que, sauf les cas simples, plusieurs espèces peuvent absorber la lumière à une même longueur d'onde, ce qui nécessite la détermination simultanée de la concentration et de <math>\epsilon^{\lambda}</math> pour chaque espèce.

Puisqu'avec une seule mesure, il n'est pas possible de déterminer plus qu'un paramètre, il faut avoir soit pour un même échantillon des mesures d'[[absorbance]] à plusieurs longueurs d'onde qui dépendront d'une même valeur de la constante d'équilibre pour ainsi cerner le ou les <math>\epsilon</math> inconnus, soit plusieurs échantillons à différentes concentrations relatives en [[Réactif (chimie)|réactifs]] dont les mesures d'absorbance dépendront des mêmes valeurs d'<math>\epsilon</math> à la même longueur d'onde pour ainsi cerner la constante d'équilibre inconnue, soit plusieurs échantillons examinés à plusieurs longueurs d'onde. On aura <math>N_C N_{\lambda}</math> mesures d'absorbance provenant de <math>N_C</math> solutions (à concentrations relatives différentes) mesurées à <math>N_{\lambda}</math> longueurs d'onde, pour évaluer au pire <math>N_E (N_{\lambda}+1)</math> inconnus provenant de <math>N_E</math> espèces chromophores associées à <math>N_E N_{\lambda}</math> valeurs d'<math>\epsilon</math> et <math>N_E</math> constantes d'équilibre. Il serait donc souhaitable d'obtenir indépendamment les valeurs d'<math>\epsilon</math> des réactifs isolés (et/ou des produits isolés) et/ou d'évaluer indépendamment, si possible, certaines des constantes d'équilibre, pour ainsi réduire le nombre total d'inconnus par détermination. De toute façon, il faut s'organiser pour avoir autant (ou plus) de données que d'inconnus (au pire <math>N_C N_{\lambda}</math> ≥ <math>N_E (N_{\lambda}+1)</math>). On se limite en général à un petit nombre de longueurs d'onde choisies pour bien répondre aux changements des concentrations des espèces chromophores, surtout aux <math>\lambda_{max}</math> des réactifs purs ou produits isolés.

==== Limitations ====
C'est une technique utilisée surtout en [[chimie]] de coordination avec les [[métal de transition|métaux de transition]]. Une limite supérieure sur <math>K</math> de 10<sup>4</sup> est habituelle, correspondant à la précision des mesures, mais cette limite dépend aussi de l'intensité de l'absorption. Idéalement, les spectres du [[Réactif (chimie)|réactif]] et du [[produit]] sont bien distincts ; un chevauchement important nécessite une attention particulière. Soit qu'on obtiendra aussi les spectres individuels du réactif et/ou du produit pour limiter la plage de calcul, et donc les valeurs <math>\epsilon</math> seront connues pour les espèces limitantes, soit le calcul effectuera par là-même une déconvolution du spectre, calcul dangereux à cause de la quantité des <math>\epsilon</math> à déterminer pour obtenir une seule constante d'équilibre.

=== Spectrométrie par RMN ===

Cette technique se limite à de cas d'échanges entre espèces relativement simples (par exemple, échanges entre isomères ou entre ligand et complexes), où les noyaux observés changent d'environnement chimique à la suite de l'échange. À l'idéal, il faut des signaux (préférablement des singulets) bien résolus (sans chevauchement).

S'il s'agit d'un équilibre lent, sur l'échelle de temps du phénomène [[Résonance magnétique nucléaire|rmn]]<ref group="note">En {{Lien  |fr   = RMN dynamique  |lang = en  |trad = Fluxional molecule }}, un équilibre suffisamment lent pour faire voir deux signaux doit procéder avec une constante de vitesse tombant sous le seuil de la coalescence des pics donné par <math>\pi \Delta \nu /\sqrt{2}</math>, où <math>\Delta \nu</math> est la différence des fréquences des signaux provenant de chaque espèce en équilibre, correspondant à <math>\Delta \delta \times \nu_0</math> où <math>\nu_0</math> est la fréquence opérationnelle du spectromètre et <math>\Delta \delta</math> est la différence des déplacements chimiques des deux signaux. Une intégration précise des deux signaux nécessite une séparation entre eux supérieure à la largeur-type d'un signal, ce qui sera facilité par une [[constante de vitesse]] de beaucoup inférieure à ce seuil. Une constante de vitesse supérieure à ce seuil donnera un seul signal. </ref> entre deux espèces détectables simultanément, le rapport de la mesure d'intégration des signaux de chaque espèce suffit à établir le rapport de concentration entre les deux, pourvu que l'on prenne les soins nécessaires à la mesure précise de l'intégration<ref group="note">En particulier, il faut un délai suffisamment long entre pulsions pour assurer une [[Imagerie par résonance magnétique#Séquence SE classique|relaxation]] quasi totale des noyaux, une [[Ligne de base (homonymie)|ligne de base]] aplanie et un déphasage quasi nul de part et d'autre des signaux.</ref>, d'où des mesures à différentes concentrations pourront quantifier la constante d'équilibre entre les deux.

Sinon et habituellement dans les situations de complexation, quand l'équilibre est rapide sur l'échelle RMN, on observe un seul signal par type de noyau pour les espèces en équilibre. Le déplacement chimique de ce genre de signal est alors perçu par l'instrument comme la moyenne <math>\bar{\delta}</math> des états contribuants, c'est-à-dire la moyenne des signaux provenant des noyaux participants, habituellement<ref group="note">Cette formulation habituelle suffit pour les systèmes d'équilibre simples, mais peut porter à confusion dans une formulation qui se veut générale, telle qu'exposée dans une [[#Particularités pour données par RMN|section ultérieure]]. On devra distinguer la concentration <math>c</math> d'un noyau contribuant à un signal donné de la concentration <math>[E]</math> de l'espèce porteuse du noyau, puisqu'une espèce peut porter plus d'un même noyau, et distinguer aussi donc la somme des concentrations de ce noyau de la somme des concentrations des espèces.</ref> pondérée par leurs concentrations <math>c</math> (ou plus précisément par leurs [[fraction molaire|fractions molaires]]),
:<math>\bar {\delta} =\frac{\sum c_i \delta_i}{\sum c_i}</math> .
Plusieurs signaux distincts, provenant de noyaux différents dans un même échantillon, peuvent ainsi être soumis au même traitement numérique pour déterminer avec plus de confiance les mêmes constantes d'équilibre. Autrement, plusieurs rapports stœchiométriques seront mesurés.

On aura donc, dans un système d'échange rapide, <math>N_C N_S</math> mesures de déplacement chimique provenant de <math>N_S</math> signaux avec <math>N_C</math> échantillons aux concentrations relatives différentes pour évaluer au pire <math>N_E (N_S +1)</math> inconnus, soit les déplacements <math>\delta_i</math> des <math>N_S</math> signaux des <math>N_E</math> espèces en équilibre et <math>N_E</math> constantes d'équilibre <math>K</math>. Les valeurs de <math>\delta</math> des noyaux dans les espèces limitantes (réactif pur et/ou produits purs) peuvent souvent être déterminées séparément pour limiter la détermination aux valeurs <math>\delta</math> et <math>K</math> autrement inconnaissables et donc réduire le nombre de valeurs inconnues, mais de toute façon il faut s'organiser pour avoir autant ou plus de données que d'inconnues (au pire <math>N_C N_S</math> ≥ <math>N_E (N_S +1)</math>).

==== Limitations ====
Cette méthode est limitée aux [[molécule]]s [[diamagnétique]]s comprenant un noyau sensible et, ce, soit bien en dessous ou bien au-dessus de la [[température]] de [[Coalescence (physique)|coalescence]] du phénomène d'échange observé. Les déplacements chimiques de référence (par exemple, du réactif isolé, dans une situation de complexation) doivent être obtenus à la même température et dans le même [[solvant]] que le mélange contenant un complexe. La précision des mesures de déplacements chimiques convient aux valeurs de <math>K</math> à déterminer allant jusqu'à environ 10<sup>4</sup>, bien que la méthode de compétition peut étendre cette plage.

== Méthodes de calcul ==

Les données de base incluront pour chaque échantillon les concentrations analytiques des réactifs mis ensemble pour constituer les espèces complexes en équilibre entre eux et avec les réactifs libres, ainsi qu'une mesure de la concentration d'une espèce ou de plusieurs espèces. Le nombre de mesures sera préférablement supérieur (et au minimum égal) au nombre de valeurs inconnues (constantes d'équilibre en cause, ainsi que les valeurs d'<math>\epsilon</math> ou de <math>\delta</math> à déterminer). Moins on aura d'inconnues à déterminer à la fois, plus chaque détermination sera fiable.

=== Linéarisations dangereuses ===

Une détermination graphique est parfois possible avec un système expérimental simple impliquant un ou deux équilibres. Cela nécessite une linéarisation avec ou sans approximations des rapports non linéaires entre [[constante d'équilibre|constantes d'équilibre]] et les [[concentration molaire|concentrations]] mesurées, d'où l'on soutirera la valeur du ou des <math>K</math> avec la pente ou l'intercepte ou avec une combinaison des deux. Il va sans dire que toute approximation amoindrira la généralité de la détermination. Même si l'on peut obtenir les valeurs exactes de la pente et de l'intercepte par calcul ([[méthode des moindres carrés]]) plutôt que par estimation visuelle, ce genre de détermination peut violer un principe de base en [[statistique]] des modèles linéaires<ref>Neter ''et al.'' (1983) discutent ce sujet en profondeur.</ref>, soit que la distribution des ''erreurs de mesure'' (erreurs affligeant les <math>y</math> dans un rapport linéaire <math>y=mx+b</math>) sera [[aléatoire]] et à [[distribution normale]] des amplitudes<ref group="note">Un modèle linéaire exige aussi que les ''variables'' (les <math>x</math> dans <math>y=mx+b</math>) soient sans erreur. Ceci est pratiquement impossible en science, car il y aura presque toujours une erreur dans toute quantité mesurable. Toutefois, York (D. York, ''Can. J. Phys.'' '''44''' (1966) 1079) a démontré que de petites erreurs dans les variables auront un effet négligeable sur la solution finale du rapport linéaire. De plus, Berkson (J. Berkson, ''J. Am. Stat. Soc.'' '''45''' (1950) 164) a démontré que ces erreurs sont admissibles si les valeurs des <math>x</math> sont ''visées'' ou ''précisées'' (par exemple en livrant un volume précis décidé à l'avance) et non pas aléatoire (comme ce sera le cas, par exemple, si l'on cherchait la relation entre [[chiffre d'affaires]] et nombres de clients, où le nombre de clients de jour en jour est aléatoire), pourvu que ces erreurs sont indépendantes des variables et des mesures. Cette indépendance n'est toutefois pas assurée. Par exemple, si la variable <math>x</math> est un [[volume]] livré par [[burette]] mal calibrée, les erreurs dans les <math>x</math> seront systématiques et non pas aléatoires. </ref>. Bien que l'on puisse s'attendre à ce que les erreurs de mesure obéiront une [[distribution normale]], ce ne sera pas le cas des ''[[fonction (mathématiques)|fonctions]]'' de ces mesures qui résulteront d'une linéarisation des [[équation]]s régissant les équilibres en cours.

En guise d'exemple, l'équation de [[Henderson-Hasselbalch]] est une linéarisation courante pour quantifier un équilibre simple. Elle peut être utilisée de manière statistiquement rigoureuse ou dangereuse. Dans le cas d'une titration d'acide faible <math>HA</math> avec une solution d'hydroxyde, on propose le modèle
:<math>pH_i = pK_a^{HA}+\log_{10} \frac {[A^-]_i}{[HA]_i} = pK_a^{HA}+\log_{10} \frac {[OH^-]_i}{[HA]_0-[OH^-]_i} = pK_a^{HA}+\log_{10} \frac {v_i[OH^-]_0}{[HA]_0-v_i[OH^-]_0}</math>
où un volume <math>v_i</math> de solution d'hydroxyde à teneur <math>[OH^-]_0</math> est livrée à une solution d'acide à teneur initiale <math>[HA]_0</math> pour ensuite mesurer le <math>pH_i</math> résultant. Cette équation a la forme
:<math>y=x+pK_a^{HA}</math>
Puisqu'ici on oppose la mesure elle-même (le <math>pH_i</math>) aux paramètres connus (les constantes <math>[HA]_0</math> et <math>[OH^-]_0</math> et la variable <math>v_i</math>), la détermination du <math>pK_a</math> sera rigoureuse, pourvu que l'on ne calcule pas de pente chimérique (voir plus bas).


Par contre, un cas contraire fait partie des travaux pratiques d'un cours de chimie d'une université américaine<ref>{{Lien web |url= http://www.chem.ufl.edu/~itl/4411L_f00/pka/pka.html|titre= Spectrophotometric Determination of the pKa of Neutral Red Indicator|langue=Anglais|consulté le=2007-12-28}}</ref>. Il s'agit d'une détermination spectrométrique du <math>pK_a</math> d'un indicateur <math>I</math>, <math>pK_a^{HI}</math>, par double application de l'équation de Henderson-Hasselbalch. On mesure l'absorbance <math>A_i^{\lambda}</math> à une ou plusieurs longueurs d'onde <math>\lambda</math> d'une solution à teneur totale en <math>I</math> de <math>[I]_0</math> lors d'une titration avec de l'hydroxyde à teneur <math>[OH^-]_0</math>, et la première application de l'équation de Henderson-Hasselbalch oppose le <math>pK_a^{HI}</math> à l'absorbance, soit
:<math> \log_{10} \frac {[I]_i}{[HI^+]_i} = \log_{10} \frac {A_i^{\lambda}-\epsilon_{HI^+}^{\lambda}\ell[I]_0}{\epsilon_{I}^{\lambda}\ell[I]_0-A_i^{\lambda}} = pH_i + pK_a^{HI}</math>
Mais le <math>pH</math> n'est pas contrôlé directement ; plutôt, on le calcule avec la seconde application de l'équation de Henderson-Hasselbalch, tout en connaissant le <math>pK_a</math> d'un tampon <math>HA</math>, <math>pK_a^{HA}</math>, ainsi que la concentration initiale du tampon, <math>[HA]_0</math>, ce qui donne
:<math> \log_{10} \frac {A_i^{\lambda}-\epsilon_{HI^+}^{\lambda}\ell[I]_0}{\epsilon_{I}^{\lambda}\ell[I]_0-A_i^{\lambda}} = pK_a^{HA}+\log_{10} \frac {v_i[OH^-]_0}{[HA]_0-v_i[OH^-]_0}+ pK_a^{HI}</math>
On y reconnaîtra la forme
:<math>y=x+pK_a^{HI}</math>
analogue à celle du premier exemple.

Le fait qu'il y ait double application de l'équation de Henderson-Hasselbalch n'est pas problématique. Le problème est que ce n'est pas la mesure <math>A^{\lambda}</math> qui est opposée aux paramètres connus, mais bien une fonction non linéaire de la mesure, plus précisément une différence de fonctions logarithmiques,
:<math>y=\log_{10} \lbrace A_i^{\lambda}-\epsilon_{HI^+}^{\lambda}\ell[I]_0 \rbrace-\log_{10} \lbrace \epsilon_{I}^{\lambda}\ell[I]_0-A_i^{\lambda} \rbrace </math> .
Bien que l'on peut espérer une distribution aléatoire des erreurs de mesure <math>A^{\lambda}</math> et que l'amplitude de ces erreurs obéira une [[distribution normale]], ce ne sera certainement pas le cas chez la quantité complexe <math>y</math> même si les <math>\epsilon</math> et le <math>[I]_0</math> sont sans erreur possible, ce qui n'est pas le cas. Au contraire, cette détermination imposera une distribution aléatoire des résidus <math>y-(x+pK_a^{HI})</math> et les amplitudes de ces résidus obéiront une distribution normale, mais il n'y a aucune signification physique ni dans la quantité <math>y</math>, ni dans les <math>y-(x+pK_a^{HI})</math>.

Un autre problème survient avec ces deux exemples : un expérimentaliste mal avisé verra dans la relation <math>y=x+pK_a</math> un modèle linéaire de forme générale <math>y=mx+b</math> et aura le réflexe de calculer une pente et un intercepte par la [[méthode des moindres carrés]], souvent à l'aide d'une fonction préconstruite d'un logiciel (par exemple Excel de Microsoft)<ref group="note">C'est exactement ce que l'on demande des étudiants en travaux pratiques de l'université américaine.</ref>. alors qu'''il n'y a pas de pente à déterminer''. Non seulement la valeur du <math>pK_a</math> ainsi calculé ne sera pas justifiable, les statistiques de confiance dans le résultat, basées sur une détermination de deux inconnues, seront alors faussées. Le <math>pK_a</math> n'est pas en fait un intercepte à déterminer en extrapolant vers <math>x = 0</math>, mais la simple moyenne des différences <math>y-x</math>, et la confiance en la valeur du <math>pK_a</math> ainsi obtenue sera donnée par la [[déviation standard]] autour de cette moyenne. La tentation de déterminer une pente chimérique est d'autant plus grande que la déviation standard du <math>pK_a</math> calculé avec une pente sera plus petite, puisque la modélisation d'une relation à l'aide de deux paramètres (pente et intercepte) sera toujours plus satisfaisante qu'à l'aide d'un seul paramètre (l'intercepte, dans le cas présent).

=== Modélisation non linéaire ===

Quand un système met en œuvre plusieurs équilibres ou quand les équilibres mettent en cause plusieurs espèces chimiques à la fois, une linéarisation devient impossible sans y imposer des restrictions (approximations). Même si l'on se conforme aux exigences d'un modèle linéaire, toute restriction rend la détermination approximative et moins générale. C'est alors qu'un traitement numérique s'impose.

Dans l'exemple ci-haut, où la linéarisation ne donnait pas un modèle linéaire valide, on aurait dû s'en tenir à une relation <math>f</math> non linéaire
:<math>A_i^{\lambda} = f (v_i, [OH^-]_0, [A]_0, pK_a^{HA}, \epsilon_{I}^{\lambda}, \epsilon_{HI^+}^{\lambda}, \ell, [I]_0, pK_a^I)</math>
En général, on travaille avec une relation
:<math>mesure(s)=f(variable(s),\ constante(s),\ inconnue(s))</math>.
On ne peut pas trouver les inconnues par solution directe. De toute façon, l'équation ne sera pas exacte, étant donné qu'il y aura des erreurs de mesure, des erreurs dans les variables, des erreurs systématiques dans les constantes et la possibilité que les paramètres inconnus ne suffiront pas ou ne seront pas les plus justes. Plutôt, on écrit
:<math>mesure(s)=calcul(s)+erreur</math>.
où les <math>calcul(s)</math> sont obtenus avec <math>f(variable(s),\ constante(s),\ inconnue(s))</math>. On cherchera le meilleur modèle <math>f</math> (en général, on ne s'attarde qu'aux paramètres inconnus quand on modélise, mais le modèle entier comprend tous les paramètres) qui fournira les moindres résidus <math>(mesure-calcul)</math>. Pour ce faire, il faut avoir au départ des estimations des valeurs inconnues et parfaire ces estimations par itération algorithmique jusqu'à ce que les résidus <math>(mesure-calcul)</math> soient amoindries — la [[méthode des moindres carrés]] assurera en même temps une [[distribution normale]] des résidus — pour en arriver à ainsi ''déterminer'' les valeurs inconnues au sein du modèle, avec une appréciation des erreurs de la détermination. Ensuite, on pourra songer à modifier le modèle, s'il y a lieu, et comparer différents modèles de manière rigoureuse.

Le problème de la minimisation des résidus n'est qu'un problème technique et il existe plusieurs algorithmes qui se vantent certains avantages. Tous doivent arriver à la même conclusion sur un même modèle décrivant un même système. Cet article cherche moins à comparer les diverses méthodes numériques qu'à assurer une approche statistiquement valide, approche qui pourra alimenter une programmation des calculs.

La méthode décrite ici suit le cheminement de Alcock ''et al.'' (1978) pour un régime général d'équilibres multiples.

=== Le modèle chimique ===

Le modèle chimique doit inclure toutes les espèces en équilibre de façon à permettre un calcul de chacune de leurs concentrations, impliquant autant d'équilibres qu'il y a d'espèces en solution<ref group="note">Tout comme dans les systèmes d'équations linéaires, il faut autant d'équations indépendantes qu'il y a de paramètres indépendants à déterminer. Avec un ensemble d'équilibres à constantes données, on trouvera la solution unique de l'ensemble des concentrations des espèces. Plus tard, à l'aide d'une mesure de la concentration d'une espèce, on trouvera la solution unique de l'ensemble des constantes d'équilibre. Il faut donc au minimum autant de quantités connues qu'il y aura d'inconnues pour obtenir une solution unique. On peut toujours définir un plus grand nombre d'équilibres que d'espèces, mais certains seront redondants parce qu'ils ne seront pas indépendants, c'est-à-dire qu'ils seront une combinaison quelconque des autres équilibres déjà définis ; on ne pourra pas déterminer l'un indépendamment de l'autre et on ne doit donc pas les définir comme s'ils étaient indépendants.</ref>. Il y a deux genres de constantes d'équilibre utilisés pour ce faire : les ''constantes générales'' et les ''constantes de formation cumulative''.

Une constante dite générale gouverne un équilibre entre n'importe quelles espèces, par exemple un équilibre d'échange de ligands entre deux [[complexe (chimie)|complexes de coordination]], par exemple

:<math>MX_2^{2+} + Y \rightleftharpoons MXY^{2+} + X </math>&nbsp; &nbsp;&nbsp; où &nbsp;&nbsp;&nbsp;<math>K = [MXY^{2+}][X]/[MX_2^{2+}][Y]</math>

Une constante de formation cumulative se limite à un équilibre entre une espèce et les réactifs irréductibles qui la forment par cumul. Comme tout ensemble en équilibre survient après avoir mélangé des réactifs, on définit donc toute espèce comme le résultat <math>A_pB_q...</math> d'une combinaison stoichiométrique et unique des réactifs irréductibles <math>A</math>, <math>B</math>, <math>...</math>
:<math>pA+qB...\rightleftharpoons A_pB_q...</math>
spécifiée par les [[stœchiométrie|coefficients de stœchiométrie]] <math>p</math>, <math>q</math>, <math>...</math>,
et la constante d'équilibre qui régit cette formation est habituellement symbolisé par un <math>\beta</math>, ainsi
:<math>\beta_{pq...}=\frac{[A_pB_q...]} {[A]^p[B]^q...}</math>
Ce faisant, nous garantissons autant de constantes que d'espèces et aucun équilibre ne sera redondant. Même les réactifs irréductibles peuvent être représentés de la même manière, avec des <math>\beta</math> symboliques,
:<math>[A]^{ _{ }} = \beta_{10...}[A]^1[B]^0...</math>&nbsp;&nbsp;&nbsp; où &nbsp;&nbsp;&nbsp; <math>\beta_{10...^{}} ={[A_1B_0...]}/{[A]^1[B]^0...}=1</math>
:<math>[B]^{ _{ }} = \beta_{01...}[A]^0[B]^1...</math>&nbsp;&nbsp;&nbsp; où &nbsp;&nbsp;&nbsp; <math>\beta_{01...^{}} ={[A_0B_1...]}/{[A]^0[B]^1...}=1</math>
:<math>\mathbf{...}</math>
pour que toutes les espèces soient traitées de façon homogène. De façon générale, la concentration de la <math>i</math> ième espèce <math>E_i</math>, formée d'une combinaison de <math>N_R</math> réactifs <math>R</math>, est
:<math>[E_i] = \beta_i \prod_k^{N_R} [R_k]^{a_{i,k}}</math>
où le coefficient de stœchiométrie <math>a_{i,k}</math> est le nombre d'équivalents du <math>k</math> ième réactif entrant dans la formation de la <math>i</math> ième espèce, et où <math>\beta_i</math> est la constante d'équilibre qui régit cet assemblage. Cette représentation harmonisée facilitera la notation à venir et la programmation des logiciels.

Il s'avère que cette deuxième sorte d'équilibre est d'utilité tout aussi générale que la première. En effet, tout ensemble d'espèces en équilibres multiples pourra être modelé à l'aide d'équilibres de formation (bien qu'ils ne seront pas toujours le meilleur choix)<ref group="note">À la section [[#Constantes dérivées et modèles équivalents|Constantes dérivées et modèles équivalents]], on verra comment certains systèmes d'équilibres seront mieux modelés autrement.</ref> et, une fois le système d'équations résolu et les <math>\beta</math> déterminés, tout autre équilibre ne sera qu'une combinaison de ces mêmes équilibres de formation, et toute autre constante ne sera qu'une combinaison de ces mêmes <math>\beta</math> et pourra donc être quantifié par la suite (voir [[#Constantes dérivées et modèles équivalents|constantes dérivées]]). Pour reprendre l'exemple d'échange de ligands entre complexes de coordination cité ci-haut, nous pouvons écrire
:<math>K = [MXY^{2+}][X]/[MX_2^{2+}][Y] = \beta_{111} \beta_{010}/\beta_{120} \beta_{001}</math>
:où <math>\beta_{111} = \frac{[MXY^{2+}]}{[M^{2+}][X][Y]}</math>, &nbsp;&nbsp;<math>\beta_{120} = \frac{[MX_2^{2+}]}{[M^{2+}][X]^2[Y]^0}</math>, &nbsp;&nbsp;<math>\beta_{010} = \frac{[X]}{[M^{2+}]^0[X][Y]^0}(=1)</math>&nbsp;&nbsp; et &nbsp;&nbsp; <math>\beta_{001} = \frac{[Y]}{[M^{2+}]^0[X]^0[Y]} (=1)</math>

Le grand avantage d'une telle formulation à l'aide d'équilibres de formation est que le calcul des concentrations (section suivante) est grandement simplifié.

Dans tous les cas, si l'expérience est conduite en milieu aqueux, il faudra inclure la dissociation de l'eau (son [[autoprotolyse]])
:<math>K_W=[H^+_{ }][OH^-]</math>
et imposer la valeur du [[autoprotolyse|produit ionique]] <math>K_W</math> appropriée à la situation<ref name=data_sources>Pour une compilation des valeurs du <math>K_W</math> et de bien d'autres constantes d'équilibre, voir A. E. Martell et R. M. Smith, ''Critical Stability Constants'', Vol. 1-6 ; Plenum Press : Londres, New York, 1974-1989. Une version électronique {{lien brisé|consulté le=2013-04-08|url=http://www.nist.gov/srd/nist46.htm|titre=version électronique}} de cette compilation est aussi disponible. Le logiciel [http://www.stanford.edu/~cpatton/constants.htm MAXC] les emploie. Une autre base de données est incorporée dans le logiciel [http://www.acadsoft.co.uk/scdbase/scdbase.htm SC-Database] ; elle inclut les constantes de solubilité et peut apporter des corrections pour les changements de température et de force ionique. Le {{lien brisé|consulté le=2013-04-08|url=http://daecr1.harvard.edu/pKa/pKa.html|titre=site de D. Evans}} affiche les valeurs de <math>pK_a</math> pour plusieurs types d'acides organiques et inorganiques. À l'aide de ces compilations, la valeur d'une constante inconnue peut être estimée à base de valeurs connues de constantes d'équilibres semblables pour bien lancer son affinement.</ref> en tant que constante connue. Si <math>H^+</math> or <math>OH^-</math> est un des réactifs, disons <math>A</math>, la dissociation de l'eau peut être représentée en utilisant la même notation que celle des équilibres de formation, par
:<math>\beta_{-10...^{ }}= K_w = {[OH^-]}/{[H^+]^{-1}[B]^0...}</math> si <math>H^+</math> est le réactif <math>A</math>, ou <math>{[H^+]}/{[OH^-]^{-1_{ }}[B]^0...}</math> si <math>OH^-</math> est le réactif <math>A</math>.
Si jamais la valeur du <math>K_W</math> n'était pas connu pour la situation expérimentale voulue, par exemple dans un mélange de solvants particulier et (ou) à une température particulière, on pourrait la considérer comme quantité inconnue à déterminer en même temps que les autres constantes inconnues, mais il serait plus sage de la déterminer auparavant, indépendamment, par exemple par la [[Graphe de Gran|méthode de Gran]], pour limiter le nombre d'inconnus à traiter par expérience et la corrélation entre les résultats.

Il va sans dire que le modèle doit être complet, dans le sens que doivent y paraître tous les équilibres enchevêtrés qui risquent d'agir sur la mesure. Toutefois, il est usuel d'omettre du modèle les espèces que l'on anticipe n'exister qu'en concentrations négligeables, par exemple les équilibres mettant en cause l'électrolyte que l'on ajoutera pour maintenir une force ionique constante ou les espèces-tampons qui maintiendront un <math>pH</math> constant. Après avoir numérisé les équilibres et jugé du succès de la modélisation, on aura l'occasion de revoir la pertinence des espèces incluses et la nécessité d'y inclure des espèces non anticipées.

=== Numérisation ===

À un ensemble de <math>\beta</math> correspondra un ensemble unique de concentrations, parce qu'elles sont bornées par les quantités des matériaux utilisées.

La quantité de chaque réactif mis en réaction, maintenant dispersée parmi toutes les espèces complexes qu'il forme ainsi qu'en forme libre, restera constante dans un échantillon donné, et sera donc connue dans chaque échantillon (ou à chaque étape d'une titration) selon les volumes et les concentrations des stocks mélangés pour préparer l'échantillon. Pour chaque réactif <math>R</math>, on aura donc une concentration analytique connue <math>[R]^{connue}</math> dans chaque échantillon. On cherchera alors les concentrations de toutes les espèces formées par ce réactif, ainsi que le reste inutilisé du réactif (réactif libre), de sorte que le total de leurs parts en <math>R</math>, <math>[R]^{calc}</math>, soit égal à <math>[R]^{connue}</math>. La somme des parts du <math>j</math>&nbsp;ième de <math>N_R</math> réactifs formant les <math>N_E</math> espèces <math>E</math>, s'écrit
:<math>[R_j]^{calc}= \sum_i^{N_E} a_{i,j} [E_i] = \sum_i^{N_E} a_{i,j} \beta_{i} \prod_k^{N_R} [R_k]^{a_{i,k}}</math>
où le coefficient stœchiométrique <math>a_{i,j}</math> indique le nombre d'équivalents du <math>j</math> ième réactif contenu dans l'<math>i</math> ième espèce. Ainsi, l'unicité des valeurs des concentrations pour chaque ensemble de <math>\beta</math> est assuré par les <math>N_R</math> <math>[R]^{connue}</math> correspondant aux <math>N_R</math> 'inconnus' <math>[R_k]</math>.

La détermination trouvera donc l'unique ensemble des <math>\beta</math> qui fixeront les concentrations des espèces qui reproduiront le mieux les mesures expérimentales et il suffira d'avoir au moins autant de mesures que de <math>\beta</math> inconnus.

La stratégie à suivre consiste donc à
* calculer les concentrations estimées des <math>N_E</math> espèces <math>E</math> en calculant les concentrations estimées des <math>N_R</math> réactifs libres <math>R</math> à partir d'estimations des valeurs des <math>\beta</math> inconnus<ref name=data_sources />, ce qui requiert que les <math>[R]^{calc}</math> et les <math>[R]^{connue}</math> soient mis en accord par ajustement des <math>[R_k]</math> de manière itérative
* comparer la mesure à ce que les concentrations ainsi estimées permettent d'anticiper, c'est-à-dire comparer la mesure réelle à celle estimée, selon le rapport entre la quantité mesurée et les concentrations dont la mesure dépend
* calculer et appliquer un ajustement aux valeurs des <math>\beta</math> inconnus
* recalculer les concentrations des réactifs libres
* re-comparer les mesures réelles et estimées
* ré-ajuster les <math>\beta</math> inconnus
* et ainsi de suite de manière itérative, jusqu'à ce que l'accord des mesures réelles et estimées ne puisse plus être amélioré, nous permettant de conclure que les <math>\beta</math> auront donc été déterminés.

==== Calcul des concentrations ====

À chaque itération de la détermination, les concentrations doivent être calculées, mais il n'est pas possible de résoudre directement les <math>N_R</math> équations parallèles
:<math>[R_j]^{connue} = [R_j]^{calc}</math>
parce qu'elles ne sont pas linéaires. Plutôt, la [[Méthode des moindres carrés#Ajustement de modèles non linéaires|méthode Gauss-Newton]] est adoptée, où l'on se rapprochera petit à petit de la solution à partir d'un début approximatif où auront été estimées les concentrations <math>[R]</math>. À la <math>\mu</math> ième itération, on calculera des corrections <math>\Delta [R_k]_{\mu}</math> à apporter aux valeurs en cours <math>[R_k]_{\mu}</math> pour générer de meilleures estimations des <math>[R_j]^{calc}</math> et qui serviront à la <math>(\mu+1)</math>&nbsp;ième itération. Ces corrections proviendront de la solution des [[série de Taylor|séries de Taylor]] (tronquées pour ne retenir que les termes de premier ordre)<ref group="note">L'expérience montre qu'il n'y a pas d'avantage à y inclure des termes d'ordre supérieur, puisque l'accélération à la solution que cela peut donner, par une réduction du nombre d'itérations requises, est insuffisante pour justifier les calculs plus compliqués que cela nécessite à chaque itération (et la programmation de ces calculs plus compliquée). </ref>
:<math>[R_j]^{connue} = [R_j]_{\mu}^{calc} + \sum_k^{N_R} \frac {\partial [R_j]_{\mu}^{calc}}{\partial [R_k]} \Delta [R_k]_{\mu} </math>
que l'on peut rassembler en notation matricielle-vectorielle ainsi
:<math>\mathbf{[R]}^{connue} = \mathbf{[R]}_{\mu}^{calc} + \mathbf{D}_{\mu}\, \mathbf{\Delta}_{\mu} </math>
où le <math>(j,k)</math>&nbsp;ième élément de la matrice <math>\mathbf{D}_{\mu}</math> sera le dérivé <math>{\partial [R_j]_{\mu}^{calc}}/{\partial [R_k]}</math><ref group="note"><math>{\partial [R_j]_{\mu}^{calc}}/{\partial [R_k]} = \sum_i^{N_E} a_{i,j}[E_i]_{\mu}a_{i,k}/[R_k]_{\mu}</math></ref> tandis que le vecteur <math>\mathbf{\Delta}_{\mu}</math> contiendra les corrections <math>\Delta [R_k]_{\mu}</math>. La solution à la <math>\mu</math> ième itération sera
:<math>\mathbf{\Delta}_{\mu} = \mathbf{D}_{\mu}^{-1}\ (\mathbf{[R]}^{connue} - \mathbf{[R]}_{\mu}^{calc})</math>
puisque la matrice <math>\mathbf{D}_{\mu}</math> sera carrée et inversible<ref group="note">Motekaitis et Martell (1982) arrivent au même résultat avec des déterminantes.</ref>{{,}}<ref group="note">Ceci illustre le grand avantage de la représentation par équilibres de formation cumulative : n'importe quel nombre d'espèces en solution sont définies en termes d'un nombre beaucoup plus petit de réactifs, ce qui nécessite la solution d'un ensemble plus petit d'équations simultanées, l'inversion d'une matrice plus petite, et donc un calcul plus rapide. À cet égard, cette approche numérique diverge de celle d'Alcock ''et al.'' (1978), qui ont cherché les concentrations de toutes les espèces à la fois. </ref>.
Chaque itération nécessitera alors un nouveau calcul de ces dérivés, ainsi que de nouvelles estimations des concentrations, jusqu'à ce que les corrections <math>\Delta [R_k]</math> deviennent insignifiantes, et on aura ainsi trouvé les concentrations finales. Le nombre d'itérations requises dépendra du point de départ, c'est-à-dire de la qualité des valeurs estimées des concentrations [R] à la première itération. Dans le cadre d'une titration, où chaque échantillon (à la suite de chaque ajout du titrant) suit l'autre en ordre, on n'aura besoin d'estimer ces concentrations qu'au début et le nombre d'itérations à chaque échantillon suivant sera réduit<ref group="note">Les valeurs finales des concentrations calculées pour un échantillon peuvent servir comme estimations au début du calcul pour l'échantillon suivant. Les dérivés que l'on aura calculés à la dernière itération de l'une serviront à la première itération de l'autre, la matrice <math>\mathbf{D}</math> correspondante aura déjà été invertie, et on aura aussitôt un premier ensemble de corrections <math>\Delta [R_k]</math> à apporter. Ainsi, quelques itérations suffiront généralement pour chaque échantillon, sauf aux points d'inflexion, où les concentrations changent plus radicalement.</ref>.

==== Affinement des constantes d'équilibre ====

L'affinement des valeurs des constantes d'équilibre inconnues se fait d'habitude en minimisant, par la [[méthode des moindres carrés]] non linéaire, une quantité <math>U</math> (aussi dénoté par <math>\chi^2</math>) appelée [[fonction objectif]] :
:<math>U=\sum_i\sum_j W_{i,j}\left(y_i-y_i^{calc}\right)\left(y_j-y_j^{calc}\right)</math>
où les <math>y</math> représentent les mesures et les <math>y^{calc}</math> sont les quantités que les concentrations des espèces permettent d'anticiper. La matrice des pondérations, <math>\mathbf {W}</math>, devrait, à l'idéal, être l'inverse de la [[matrice des variances et covariances]] des mesures, mais il est rare que ces quantités soient connaissables à l'avance<ref group="note">Quand elles le sont, la [[Espérance mathématique|valeur anticipée]] du <math>U</math> est 1, ce qui signifie que les mesures auront été reproduites ''en deçà des erreurs expérimentales''. </ref>. Si les mesures sont indépendantes l'une de l'autre, les [[covariance]]s seront nulles et on pourra anticiper les [[variance (statistiques et probabilités)|variances]] relatives, dans lequel cas <math>\mathbf {W}</math> sera une matrice diagonale, et la quantité à minimiser se simplifie ainsi
:<math>U=\sum_i W_{i,i}\left(y_i-y_i^{calc}\right)^2</math>
où <math>W_{i,j}=0</math> quand <math>j \ne i</math>. Des pondérations unitaires, <math>W_{i,i} = 1</math>, sont souvent utilisées<ref group="note">Dans ce cas, la [[Espérance mathématique|valeur anticipée]] du <math>U</math> est la [[Moyenne#Moyenne quadratique|moyenne quadratique]] des erreurs expérimentales.</ref>, mais, à moins que les données soient de fiabilité égale, les résultats seront biaisés par les données moins fiables.

Les éléments sur la diagonale <math>W_{i,i}</math> peuvent être estimés par la [[propagation des erreurs]] avec
:<math>1/W_{i,i} = \sigma^2_i = \sigma^2(y_i) + \sum_j \left (\frac {\partial y_i^{calc}}{\partial Q_j} \right)^2 \sigma^2(Q_j) </math>
pour tous les paramètres <math>Q</math> (les variables et constantes connues) qui ne seront pas déterminés mais qui constituent des sources d'erreurs expérimentales, où <math>\sigma(Q_j)</math> est une estimation réaliste de l'incertitude sur la valeur du <math>j</math> ième paramètre <math>Q</math><ref group="note">On présume ici que ces sources d'erreurs sont indépendantes, ce qui est le plus souvent le cas, sinon on devra estimer leurs covariances <math>\sigma(Q_j,Q_k)</math> et ajouter au calcul des <math>\sigma^2_i</math> les contributions appropriées, soit <math>({\partial^2 y_i^{calc}}/{\partial Q_j \partial Q_k} )\, \sigma(Q_j, Q_k)</math>.</ref>. Ceci reconnaît que chaque paramètre n'aura pas nécessairement une influence uniforme sur tous les échantillons, et la contribution de chaque résidu <math>(y-y^{calc})</math> sera désaccentuée selon son incertitude cumulée de toutes les sources d'erreur.

On peut en principe trouver le <math>U</math> minimum en mettant à zéro les dérivées de <math>U</math> par rapport à chaque paramètre inconnu <math>P</math>, mais on ne peut pas en retirer les valeurs des <math>P</math> directement<ref group="note">Ceci générera les équations simultanées
:<math> \frac {\partial U}{\partial P_k} = -2 \sum_i W_{i,i}\left(y_i-y_i^{calc}\right) \sum_k \frac {\partial y_i^{calc}}{\partial P_k} = 0</math>,
que l'on regroupe en forme matricielle-vectorielle avec <math>\mathbf{J}^T \mathbf{W} (\mathbf{y} - \mathbf{y}^{calc})</math>,
où la matrice <math>\mathbf{J}</math>, appelée [[matrice jacobienne]], contiendra comme éléments les dérivés <math>{\partial y_i^{calc}}/{\partial P_k}</math>. La méthode de la [[Algorithme du gradient|descente de gradient]] présume qu'à l'approche du minimum, les corrections à apporter aux <math>P</math> pour en arriver aux valeurs finales <math>P^{\infty}</math> seront approximativement
:<math> \Delta P_k = P_k^{\infty} - P_k \approx {\partial U}/{\partial P_k}</math>
et donc le vecteur de corrections sera estimé avec <math>\mathbf{\Delta} = \mathbf{J}^T \mathbf{W} (\mathbf{y} - \mathbf{y}^{calc})</math>. Cependant, cette méthode est inefficace car elle nécessite une pondération (une optimisation) des corrections, soit parce qu'elles sont trop grandes loin du minimum ou trop petites proche du minimum, ce qui requiert des re-calculs lors d'une même itération. </ref>. Plutôt, tout comme pendant le [[#Calcul des concentrations|calcul des concentrations]] (section précédente), la [[Méthode des moindres carrés#Ajustement de modèles non linéaires|méthode Gauss-Newton]] exprime les mesures sous forme de [[série de Taylor|séries de Taylor]] tronquées
:<math>y_i = y_i^{calc} + \sum_k \frac {\partial y_i^{calc}}{\partial P_k} \Delta P_k</math>
ou, en forme matricielle-vectorielle,
:<math> \mathbf{y}= \mathbf{y}^{calc}+\mathbf{J\, \Delta}</math>
où <math>\mathbf{J}</math> est la matrice des dérivées, appelée [[matrice jacobienne]], et où le vecteur <math>\mathbf{\Delta}</math> contient les corrections <math>\Delta P</math>. Cette fois, on pondère les résidus pour empêcher que le résultat final ne soit biaisé par les erreurs dans les autres paramètres, ainsi
:<math> \mathbf{W} (\mathbf{y}- \mathbf{y}^{calc}) = \mathbf{W\, J\, \Delta}</math>
Les corrections <math>\Delta P</math> sont calculées avec
:<math> \mathbf{\Delta} = (\mathbf{J}^T \mathbf{W J})^{-1} \mathbf{J}^T \mathbf{W} (\mathbf{y}- \mathbf{y}^{calc} ) </math>
où l'exposant T indique la matrice transposée. La matrice <math> (\mathbf{J}^T \mathbf{W J})^{-1}</math> est parfois appelée la matrice hessienne (bien que le nom [[matrice hessienne]] désigne aussi la matrice des dérivées secondes). Pour fins ultérieures, nous la représenterons par <math>\mathbf{H}</math>. Les corrections ainsi calculées seront ajoutées aux valeurs des <math>P</math> actuelles pour générer de meilleures estimations pour la prochaine itération. Les concentrations des espèces, les <math>y^{calc}</math>, les pondérations <math>W</math> et les dérivées dans <math>\mathbf{J}</math> seront tous recalculées pour générer à la prochaine itération une nouvelle série de corrections, et ce de manière répétée jusqu'à ce que les corrections deviennent insignifiantes et que le <math>U</math> soit plus ou moins stabilisé. Alors, on aura déterminé les valeurs finales des <math>P</math>.

===== Modification de Levenberg-Marquardt =====

Aussi appelée méthode ou algorithme de Marquardt-Levenberg.

Dépendant du point de départ, les corrections de Gauss-Newton peuvent être largement excédentaires, dépassant le minimum, ou menant à une augmentation du <math>U</math> (ce qui causerait normalement un affinement avorté) ou même causer des oscillations autour du minimum. Dans d'autres situations, l'approche du minimum peut être lente. Pour amortir les corrections trop grandes ou accélérer l'atteinte du <math>U</math> minimal, on peut faire appel à l'[[Algorithme de Levenberg-Marquardt|algorithme de Marquardt-Levenberg]], couramment utilisée, et appliquer des corrections modifiées
:<math> \mathbf{\Delta= (J}^T \mathbf{W J} +\lambda \mathbf{I)}^{-1} \mathbf{J}^T \mathbf{W} ( \mathbf{y}- \mathbf{y}^{calc} )</math>
où <math>\lambda</math> est un paramètre ajustable, et <math>\mathbf{I}</math> est la [[matrice identité]]. Un <math>\lambda</math> non nul oriente la recherche du <math>U</math> minimum vers la direction de la [[Algorithme du gradient|descente de gradient]], <math>\mathbf{J}^T \mathbf{W} ( \mathbf{y}- \mathbf{y}^{calc})</math>, qui résulte de la minimisation directe de <math>U</math> en mettant à zéro tous ses dérivés par rapport aux paramètres <math>P</math>. Cette technique, qui est d'utilité générale pour résoudre les systèmes d'équations non linéaires, exige dans le cas des déterminations de constantes d'équilibre un certain nombre de re-calculs itératifs des concentrations pour tester si la valeur actuelle de <math>\lambda</math> reste utile.

===== Modification de Potvin =====

Puisque chaque itération sur les <math>\beta</math> entraîne un nouveau calcul des concentrations, lui-même itératif, les re-calculs nécessités par la technique de Marquardt-Levenberg lors d'une même itération sont coûteux, surtout s'il y a un grand nombre de données à traiter. Le même problème survient avec d'autres méthodes d'[[Optimisation (mathématiques)|optimisation numérique]] à paramètre ajustable, telles que les méthodes de [[BFGS|Broyden-Fletcher-Goldfarb-Shanno]] ([[recherche linéaire (optimisation)|recherche linéaire]] du paramètre optimal) ou de Hartley-Wentworth (recherche parabolique)<ref>Hartley, H. O. ''Technometrics'' (1961), ''3'', 269 ; Wentworth, W. E. ; W. W. Hirsch ; E. Chen. ''J. Phys. Chem.'' (1967), ''71'', 218.</ref>.

Ayant noté que ce sont les corrections positives aux valeurs sous-estimées des <math>\log_{10} \beta</math> (ou négatives aux valeurs sur-estimées des <math>\beta</math>) qui produisent un dépassement du <math>U</math> minimum, tandis que les corrections négatives ne le font pas, et que la taille de ces corrections excessives grandit de façon exponentielle plus on est éloigné du minimum, Potvin (1992a) a proposé une simple modification logarithmique des corrections positives, soit pour la correction <math>\Delta_q</math> du <math>q</math> ième <math>\log_{10}\beta</math>
:<math>\Delta^{mod}_q = \log_{10} \,(ln\,\Delta_q + 1)</math>
Cette formulation découle d'une solution approximative des séries de Taylor à ordre infini. Les corrections ainsi modifiées sont de taille beaucoup plus raisonnable, surtout si on est loin du minimum. Bien que ces corrections modifiées puissent quand même dans certains cas mener à un léger dépassement du minimum ou même à une augmentation du <math>U</math>, ce ne sera que temporaire puisque l'itération suivante reviendra dans la bonne direction sans dépassement. L'algorithme limite aussi toute correction négative si la [[Algorithme du gradient|descente du gradient]] propose au contraire une correction positive. Le grand avantage de cette modification est son coût minime.

=== Particularités pour données spectrophotométriques ===

Selon le modèle chimique général exposé plus haut, la [[loi de Beer-Lambert]] peut être ré-écrite en termes des concentrations des espèces <math>E</math>
:<math>A^{\lambda}=\ell \sum_i {\epsilon^{\lambda}_i [E_i]}</math>
qui, en notation matricielle, donne
:<math>\mathbf{A}=\ell \, \mathbf{e} \,\mathbf{[E]}</math>
où la matrice <math>\mathbf{e}</math> contient les <math>\epsilon^{\lambda}</math>. On peut distinguer les espèces non chromophores des chromophores avec les valeurs d'<math>\epsilon</math> des espèces non chromophores obligatoirement zéro et tenues à zéro en tant que paramètres fixes. Si les valeurs d'<math>\epsilon</math> d'une espèce particulière (par exemple, une espèce limitative) sont connues, elles pourront également être tenues fixes.

Il y a deux approches généralement adoptées pour le calcul des constantes d'équilibre et des <math>\epsilon</math> inconnus. On peut ré-exprimer les <math>\epsilon</math> en fonctions des absorbances et écrire
:<math>\mathbf{A}= \{ (\mathbf{[E]}^T \mathbf{[E]})^{-1} \mathbf{[E]}^T \mathbf{A}\} \mathbf{[E]}</math> ,
ce qui permettra un affinement simultané des constantes d'équilibre et des <math>\epsilon</math> inconnus<ref group="note">Mis à part le traitement mathématique spécial que cela exige, il se peut très bien qu'à un stage intermédiaire de l'affinement, les corrections aux constantes d'équilibre « divergent » de celles aux <math>\epsilon</math>, c'est-à-dire qu'une série de corrections produit une augmentation des absorbances calculées (<math>y^{calc}</math>) alors que l'autre tente de les réduire, pour ainsi ralentir ou stopper le progrès.</ref>. L'autre approche, celle utilisée par les auteurs de Hyperquad<ref name="hyperquad">[http://www.hyperquad.co.uk/hq2000.htm Hyperquad]</ref> et de Specfit<ref name="Specfit" /> par exemple, consiste à séparer le calcul des <math>\epsilon</math> de celui des constantes d'équilibre, de n'affiner que les constantes d'équilibre et de calculer les <math>\epsilon</math> avec les concentrations résultantes. Ainsi, en partant d'une série de valeurs estimées des <math>\epsilon</math>, on affine les constantes d'équilibre en optimisant l'accord du modèle avec les mesures d'absorbance à l'aide de la jacobienne, comme décrit ci-haut, puis les <math>\epsilon</math> sont mis à jour avec
:<math>\mathbf{e} = \{(\mathbf{[E]}^T \mathbf{[E]})^{-1} \mathbf{[E]}^T \mathbf{A}\} / \ell</math>
et les nouvelles concentrations <math>[E]</math> qui en résultent<ref group="note">Cette ruse affine les concentrations (par l'entremise des constantes d'équilibre) tout en proférant de nouvelles estimations plus concordantes des valeurs des <math>\epsilon</math>. C'est une approche qui assure que les deux genres de paramètres seront toujours de mèche et ne divergeront jamais. Même si les <math>\epsilon</math> ne sont pas corrigés en même temps que les constantes d'équilibre, la jacobienne utilisée comprend les dérivés par rapport aux <math>\epsilon</math> pour quand même informer le calcul des corrections aux constantes d'équilibre. Cette utilisation de la jacobienne complète évite de biaiser l'accord du modèle et de tomber dans un minimum local dû à l'optimisation d'un seul genre de paramètre. En plus, elle permet un calcul ultime des incertitudes sur les <math>\epsilon</math> déterminés.</ref>. Ensuite, on utilise ces nouvelles estimations des <math>\epsilon</math> pour lancer un nouvel affinement des constantes d'équilibre, ce qui mène à une nouvelle série d'estimations des <math>\epsilon</math>, et ainsi de suite. Ce ping-pong continue jusqu'à ce que les deux familles de paramètres ne changent plus. Les auteurs de Specfit<ref name="Specfit" /> montrent comment trouver les dérivés de la matrice [[pseudo-inverse]] <math>(\mathbf{[E]}^T \mathbf{[E]})^{-1} \mathbf{[E]}^T</math>.

=== Particularités pour données par RMN ===

La formulation usuelle, présentée au départ, qui relie la mesure <math>\bar{\delta}</math> aux fractions molaires des noyaux participants, <math>c_i/\Sigma c_i</math>, ne convient pas ici et peut même induire en erreur<ref group="note">L'expression semble non linéaire en <math>c</math>, et on serait mené à construire la jacobienne avec des dérivés à deux termes, c'est-à-dire
:<math>\frac {\partial \bar{\delta}}{\partial \beta_m} = \sum_i^{N_N} \frac {\partial \bar{\delta}}{\partial c_i} \frac {\partial c_i}{\partial \beta_m} </math>
:<math>= \sum_i^{N_N} \{  \frac {\delta_i}{\sum_j c_j} - \frac {\sum_j \delta_j c_j }{(\sum_j c_j)^2} \} \frac {\partial c_i}{\partial \beta_m} </math>
:<math>= \frac {1}{ \sum_j c_j} \sum_i^{N_N} (\delta_i - \bar{\delta}) \frac {\partial c_i}{\partial \beta_m} </math>
:<math>= \frac {1-N_N \bar{\delta}}{ \sum_j c_j} \ \sum_i^{N_N} \delta_i \frac {\partial c_i}{\partial \beta_m} </math> ,
pour <math>N_N</math> noyaux contribuant au signal. Ceci impliquerait que le dénominateur <math>\Sigma c</math> serait sensible aux perturbations des paramètres <br /><math>\beta</math>, alors qu'en réalité il reste constant dans un même échantillon. Les dérivés seraient ainsi faussés. </ref>. Puisque tous les noyaux contribuant à un signal donné proviennent du même réactif, dont la concentration totale est connue et constante, et puisqu'une même espèce porteuse peut porter plus qu'un de ce réactif, une représentation plus générale qui reprend la notation utilisée ailleurs dans cet article relie un signal provenant du <math>k</math> ième réactif aux concentrations d'espèces avec
:<math>\bar{\delta} = \frac {1}{[R_k]^{connue}} \sum_i^{N_E} \delta_i a_{i,k} [E_i]</math>
L'utilisation ici de la concentration analytique <math>[R_k]^{connue}</math>, plutôt que la somme des parts appartenant à chaque espèce, <math>[R_k]^{calc}</math>, renforce le fait que le dénominateur commun à toutes les fractions molaires est constant et ne varie pas avec les <math>\beta</math><ref group="note">Ceci donne le dérivé plus simple et plus correct
:<math>\frac {\partial \bar{\delta}}{\partial \beta_m} = \frac {1}{[R_k]^{connue}} \sum_i^{N_E} \delta_i a_{i,k} \frac {\partial [E_i]}{\partial \beta_m} </math> .</ref>. Lors du calcul des concentrations à chaque itération sur les <math>\beta</math>, les <math>[R_k]^{calc}</math> seront de toute façon ajusté de sorte à égaler les <math>[R_k]^{connue}</math>.

En notation matricielle, on a
:<math>\mathbf{[R]}^{connue} \mathbf{\bar{\delta}} = \mathbf{a [E] d}</math>
où la matrice <math>\mathbf{d}</math> contient les éléments <math>\delta_i</math>. Les auteurs de HypNMR<ref group="note">Ce que fait le logiciel EQNMR (voir la section [[#Logiciels|Logiciels]]) n'est pas clair.</ref> procèdent comme pour les données spectrophotométriques, c'est-à-dire que la jacobienne inclut les dérivés par rapport aux <math>\beta</math> et aux <math>\delta</math>, mais que seuls les <math>\beta</math> sont corrigés alors que les <math>\delta</math> sont mis à jour à partir des nouvelles concentrations résultantes, avec
:<math>\mathbf{d} = [(\mathbf{a [E]})^T (\mathbf{a [E]})]^{-1} (\mathbf{a [E]})^T \mathbf{[R]}^{connue} \mathbf{\bar{\delta}} </math>

== Analyse des résultats ==

=== Fiabilité de la détermination et affinement du modèle ===

Une détermination numérique constitue un test d'un modèle, et non pas une preuve de sa pertinence. On peut examiner la fiabilité du modèle à l'aide de l'accord-type, des incertitudes et des corrélations et songer à modifier le modèle pour une détermination plus fiable. Cependant, la détermination cesse alors d'être une mesure de constantes d'équilibres connus et risque de devenir une découverte d'équilibres<ref group="note">L'obtention d'un meilleur accord avec les données en incluant une espèce, surtout une inattendue, ne constitue pas une preuve absolue de l'existence de cette espèce. Plusieurs revues scientifiques requièrent des preuves indépendantes de nouvelles espèces pour soutenir le modèle chimique. Par exemple, la description de la revue ''Polyhedron'' précise que « tout manuscrit ne rapportant que des constantes de stabilité obtenues par titration potentiométrique sans preuve supplémentaire (e.g. spectroscopique) ne sera acceptable » (traduction de l'auteur) ({{Lien web |url= http://www.elsevier.com/wps/find/journaldescription.authors/218/description#description|titre=Polyhedron (Elsevier) description for authors|langue=Anglais|consulté le=2007-12-23}}).</ref>. Cela doit se faire sagement, en se guidant avec des comparaisons impartiales entre modèles.

L'incertitude dans la valeur du <math>j</math> ième paramètre <math>P</math> est fournie par le <math>j</math>, <math>j</math> ième élément (le <math>j</math> ième sur la diagonale) de la matrice <math>\mathbf{H}</math>:

:<math>\sigma^2_j = \sigma^2_0 \mathbf{H}_{j,j}</math>

où <math>\sigma_0</math> est l'incertitude d'une observation à pondération 1, [[Critères de dispersion|l'accord-type]], qui peut être estimé (selon Alcock ''et al.'', 1978) avec

:<math>\sigma^2_0 = U/(N_D-N_P)</math>
pour <math>N_P</math> paramètres déterminés à partir de <math>N_D</math> données expérimentales.

D'un point de vue statistique, l'incertitude dans la valeur d'un paramètre dénote une plage de valeurs, la taille de laquelle dépendra du niveau de confiance que l'on désire, qui générera des modèles indiscernables. Ainsi, les incertitudes reflètent l'incapacité des valeurs des paramètres de reproduire les données. Inversement, les incertitudes reflètent l'incapacité des données expérimentales de préciser les valeurs des paramètres. Certaines modifications à la conception ou à la conduite de l'expérience pourraient plus précisément établir les valeurs des paramètres incertains<ref group="note">Les profils des concentrations des espèces ou les « sensibilités » des données (rapportées par les éléments de la matrice jacobienne, <math>{\partial y_i^{calc}}/{\partial P_k}</math>) pourraient indiquer quelles données s'appuient le plus sur la valeur d'un paramètre particulier, et ainsi suggérer des modifications possibles à l'expérience (étendre la plage des données ou ajouter des données interpolantes) ou de nouvelles expériences (par exemple, à d'autres concentrations relatives des réactifs) pour accroître la concentration d'une espèce gouvernée par le paramètre.</ref>. Autrement, il se peut qu'un paramètre hautement incertain puisse être laissé tombé du modèle chimique sans dégradation « importante » de l'accord du modèle avec les données.

Les coefficients de corrélation entre les valeurs des paramètres sont rapportés par les éléments hors-diagonale de la matrice <math>\mathbf{H}</math>. Entre les valeurs des <math>j</math> ième et <math>k</math> ième paramètres, on calcule
:<math>\sigma_{j,k} = \sigma^2_0 \mathbf{H}_{j,k}/\sigma_{j} \sigma_{k}</math>
Ceux-ci reflètent l'interdépendance des paramètres en modélisant les données, ''i.e.'' l'importance d'inclure chaque paramètre dans le modèle chimique. Inversement, les coefficients de corrélation reflètent l'incapacité des données à différencier entre les paramètres. Ici encore, certaines modifications expérimentales pourraient y remédier, mais il se peut qu'une paire de paramètres dont les valeurs sont hautement co-reliées puisse être remplacée dans le modèle chimique par un seul paramètre, sans dégradation « importante » de l'accord du modèle avec les données.

Par ailleurs, il se peut que le modèle chimique donne un accord « insatisfaisant » avec les données, selon la taille du <math>\sigma_0</math> et celle des résidus, mais il serait utile de savoir ce qui constitue un accord « satisfaisant ». Selon Hamilton (1964), si la condition pour <math>N_D</math> données
:<math>\sum_i^{N_D} W_{i,i}(y^{obs}-y^{calc})^2 < \sum_i^{N_D} W_{i,i} \sigma^2_i</math>
est remplie, l'accord est satisfaisant<ref group="note">Cette expression est dérivée de la condition <math>R<R_{lim}</math> de Hamilton et de ses définitions des facteurs <math>R</math> et <math>R_{lim}</math>. </ref>. La quantité <math>\sigma_i</math> représente l'incertitude ''anticipée'' sur la <math>i</math> ième mesure. Si l'on suit la pratique prescrite ci-haut, on anticipera les valeurs de ces <math>\sigma_i</math> en prédisant à quel degré les erreurs expérimentales (estimées et anticipées) dans les paramètres fixes <math>Q</math> affecteront les mesures prédites (<math>y^{calc}</math>). Si, aussi, on utilise ces <math>\sigma_i</math> dans les pondérations, avec <math>W_{i,i} = 1/\sigma^2_i</math>, alors la condition qui indiquera un accord satisfaisant entre <math>y^{obs}</math> et <math>y^{calc}</math> deviendra
:<math>\sum_i^{N_D} W_{i,i}(y^{obs}-y^{calc})^2 < N_D</math>
ou, écrit plus simplement, <math>U<N_D</math> pour <math>N_D</math> données. C'est-à-dire qu'un accord satisfaisant donne des écarts entre mesures<br /> (<math>y_i^{obs}</math>) et calculs (<math>y_i^{calc}</math>) qui, globalement sinon à chaque fois, tombent en deçà des <math>\sigma_i</math>, la marge d'incertitude que l'on s'accordait au départ.

Dans le cas d'un accord insatisfaisant, l'inclusion d'autres espèces (et d'autres paramètres <math>\beta</math>) pourrait l'améliorer. Étant donné que l'ajout d'un paramètre d'habitude améliorera l'accord, alors que l'élimination d'un paramètre d'habitude l'empirera, il devient important de comprendre ce qui constitue une dégradation ou amélioration « importante ». Une altération d'un modèle chimique, surtout l'inclusion d'une espèce inattendue ou la mise de côté d'une espèce attendue, doit être guidée par le bon sens chimique et être impartial. Pour aider une décision impartiale si l'on expérimente avec divers modèles chimiques, le test de Hamilton<ref group="note">En anglais, « Hamilton R-ratio test ».</ref> (Hamilton, 1964) utilisé couramment en cristallographie, permet aux données de décider si un modèle alternatif devrait être rejeté ou accepté.

Finalement, les mesures elles-mêmes ainsi que les paramètres <math>Q</math> influenceront la qualité de l'accord. Par exemple, certaines [[Tendance centrale|données extrêmes ou aberrantes]] peuvent être « problématiques » en ce que leur mise à l'écart améliore de façon « importante » la qualité de l'accord, et ainsi réduit les incertitudes dans les <math>P</math>, contrairement à la règle générale que l'accord et les incertitudes seront améliorés par un plus grand nombre de données. Par ailleurs, les résidus <math>y^{obs}-y^{calc}</math> peuvent être co-reliés, c'est-à-dire que les <math>y^{obs}</math> ne sont pas distribués de façon aléatoire de part et d'autre des <math>y^{calc}</math>, ce que la méthode des moindres carrés supposera<ref group="note">Les résidus co-reliés sont très facilement décelés avec les titrations, et le degré de leur corrélation peut être mesuré. Potvin (1994) donne une formule pour les données de titration dérivée de Neter ''et al.'' ({{Ouvrage|prénom1=John|nom1=Neter|auteur2=William Wasserman|auteur3=Michael H. Kutner|titre=Applied Linear Regression Models|éditeur=R. D. Irwin, Homewood, IL|année=1983|pages totales=547|isbn=978-0-256-02547-7|id=ISBN}}). Les résidus hautement co-reliés signalent d'habitude une erreur systématique dans l'un ou l'autre des paramètres fixes du modèle (<math>Q</math>) (volumes, concentrations des réactifs). Aussi, certains logiciels permettent l'inclusion d'impuretés au carbonate contenues dans les réactifs alkalins (venant du CO<sub>2</sub> atmosphérique), bien que les [[Graphe de Gran|tracés de Gran]] peuvent les quantifier (Martell and Motekaitis, 1992). Finalement, la précipitation soupçonnée mais non détectée d'hydroxydes de métaux de transition, que certains logiciels peuvent anticiper, peut justifier l'exclusion de données au-dessus d'un certain seuil de pH sur la base des valeurs connues de [[Produit de solubilité|produits de solubilité]].</ref>. Pour remédier à de tels problèmes, on peut omettre certaines données, ou déplacer la pondération en changeant les <math>\sigma(Q)</math>, ou changer les <math>Q</math> eux-mêmes, ou même les affiner aux côtés des paramètres <math>P</math> comme s'ils devaient être déterminés (ce que certains logiciels permettent). Ce genre de bricolage pour la simple amélioration de l'accord biaise le modèle au risque d'une perte de sens. Le bon sens chimique, plutôt qu'un penchant pour un résultat, devrait guider tout changement au modèle, aux paramètres fixes, aux données ou à leur pondération, et le mal que l'on se donnerait pour améliorer un accord ou un modèle pourraient être orientés à améliorer la qualité des données (''i.e.'' la confiance en elles)<ref group="note">En guise d'exemple d'un changement justifiable aux paramètres fixes, Martell and Motekaitis (1992) décrivent une situation où un mauvais accord a mené à l'identification d'une impureté dans un réactif, qui pouvait ensuite être corrigée.</ref>.

Toutefois, il peut être utile parfois de rigoureusement comparer les résultats découlant d'altérations judicieuses au modèle. L'omission ou la désaccentuation de données et l'altération de paramètres fixes donnent lieu à des modèles compétiteurs où les matrices <math>\mathbf{W}</math> diffèrent, et un test de Hamilton modifié<ref group="note">Le test de Hamilton (Hamilton, 1964) compare deux modèles obtenus avec application de la même pondération, ''i.e.'' la même matrice <math>\mathbf{W}</math>, aux mêmes données. Si l'on compare deux modèles résultant d'une pondération différente, d'expériences différentes, de différents groupes de données, ou de différentes valeurs des paramètres fixes <math>Q</math>, et donc résultant d'une matrice <math>\mathbf{W}</math> différente, un test qui égalise l'effet de la pondération peut être utilisé (Potvin, 1994).</ref> peut décider lesquels sont différents de façon statistiquement significative. Ce test modifié est aussi utile pour la comparaison de résultats provenant d'expériences séparées, avec différentes données et différentes matrices <math>\mathbf{W}</math>.

=== Erreurs expérimentales ===

Comme indiqué plus tôt, les incertitudes calculées avec la matrice <math>\mathbf{H}</math> reflètent la qualité du modèle et connotent sa « déterminabilité ». Les valeurs des paramètres et leurs incertitudes seront bien reproduites si l'expérience était répétée sous des conditions identiques, mais la « reproductibilité » d'une détermination dénote l'attente de résultats statistiquement indiscernables à partir de mesures complètement indépendantes, à l'idéal par différents praticiens à l'aide d'instruments différents et différentes concentrations des mêmes matériaux de différentes provenances. Le plus souvent, une telle diversité de sources de données n'est pas possible<ref group="note">Même lorsque des données de sources diverses sont disponibles, elles ne sont pas nécessairement toutes utiles. En 1982, Braibanti ''et al.'' ont analysé la pratique de sept laboratoires et leur variance en déterminant les mêmes équilibres chimiques ({{article|langue=en|prénom=A.|nom=Braibanti|coauteurs=F. Dallavalle, G. Mori and B. Veroni|titre=Analysis of variance applied to determinations of equilibrium constants|journal=Talanta|pages=725–731|date=1982}}), et a rejeté trois des sept séries de résultats pour arriver à des moyennes « globales ». </ref>. La répétition d'une même expérience demeure toutefois utile pour amoindrir les effets d'erreurs aléatoires dans certaines sources d'erreurs systématiques <math>Q</math><ref group="note">À moins d'utiliser un équipement mal réglé, les erreurs aléatoires d'échantillonnage et de mesure s'amoindriront par annulation. Si la préparation d'un échantillon implique le mélange de certains volumes des mêmes solutions, les répétitions réduiront l'effet d'erreurs aléatoires dans ces volumes, mais pas dans les concentrations des solutions. L'utilisation de solutions fraîchement préparées réduira l'effet d'erreurs aléatoires dans leurs préparations (en masses de substance et volumes de solvant), mais pas dans leurs compositions, à moins d'utiliser des lots différents de la même substance. Potvin (1994) a décrit une méthode de calcul de constantes d'équilibre à partir d'expériences de titration qui réduit l'effet d'erreurs aléatoires dans les sources d'erreurs systématiques, au-delà des effets de pondération et de répétition d'expériences.</ref>.

L'estimation de « l'erreur expérimentale » dans une constante d'équilibre peut donc se faire à l'aide d'une seule valeur de <math>\sigma</math> provenant d'une seule détermination, ou de plusieurs déterminations répétées pour amoindrir les effets d'erreurs aléatoires dans certaines sources d'erreurs systématiques <math>Q</math>, jusqu'à la combinaison d'expériences complètement indépendantes où les effets de toutes les sources d'erreurs systématiques seront amoindris. Donc, toute estimation « d'erreur expérimentale » devrait aussi communiquer la diversité des données utilisées pour l'estimation. Toutefois, la simple prise d'une moyenne des valeurs séparément déterminées ne tiendra pas compte de la fiabilité inégale des déterminations, telle que rapportée par les incertitudes calculées dans chaque détermination. Plutôt, la moyenne <math>\bar{P}</math> des valeurs individuelles pondérées par leurs incertitudes s'appuiera davantage sur les valeurs les moins incertaines avec
:<math> \bar{P} = \frac {\sum_{n=1}^N P_n/\sigma_n^2(P_n)}{\sum_{n=1}^N 1/\sigma_n^2(P_n)}</math>
où <math>\sigma_n(P_n)</math> rapporte l'incertitude de la <math>n</math> ième de <math>N</math> déterminations d'un même paramètre <math>P</math>. Pourvu que les tailles relatives des pondérations soient justes, cette moyenne sera insensible aux valeurs absolues de ces pondérations. De même, on peut quantifier « l'erreur expérimentale » du <math>\bar{P}</math> avec l'écart-type <math>\bar{\sigma}</math> autour de la moyenne, où les écarts <math>(\bar{P} - P_n)</math> sont pondérés par ces mêmes incertitudes, selon Potvin (1994) :
:<math> (N-1) \bar{\sigma}^2(P) = N \frac {\sum_{n=1}^N (\bar{P} - P_n)^2/\sigma_n^2(P_n)}{\sum_{n=1}^N 1/\sigma_n^2(P_n)}</math>

=== Constantes dérivées et modèles équivalents ===

Si l'on calcule une constante d'équilibre qui est fonction de constantes de formation que l'on a déterminées, telle qu'un <math>K_a</math>, l'incertitude d'une telle constante ''dérivée'' n'est pas une simple fonction des incertitudes dans les constantes déterminées, comme le voudraient les règles normales de la [[Propagation des erreurs|propagation d'erreurs]], puisque cela requiert que les sources d'erreur soient indépendantes alors que les constantes déterminées par les mêmes données sont co-reliées. En guise d'exemple, pour la protonation d'une substance dibasique <math>L</math>,
:<math>K_{a1} = \frac {[LH^+]}{[H^+][L]} = \beta_{LH^{+}}</math> , ou <math>pK_{a1} = -log \beta_{LH^{+}}</math> et
:<math>K_{a2} = \frac {[H^+][LH^+]}{[LH_2^{2+}]} = \frac {[H^+]^2[L]}{[LH_2^{2+}]} \frac {[LH^+]}{[H^+][L]} = \frac {\beta_{LH^{+}}}{\beta_{LH_2^{2+}}}</math> , ou <math>pK_{a2} = -log \beta_{LH^{+}} + log \beta_{LH_2^{2+}}</math>
L'incertitude et la variance sur la valeur de <math>pK_{a1}</math> sont les mêmes que sur <math>log \beta_{LH^{+}}</math> mais la variance (l'incertitude au carré) sur la valeur de <math>pK_{a2}</math>, <math>\sigma^2(pK_{a2})</math>, n'est pas nécessairement la somme des variances sur <math>log \beta_{LH^{+}}</math> et <math>log \beta_{LH_2^{2+}}</math>, à cause de la corrélation (d'habitude) non nul entre les deux <math>log \beta</math>. En fait,
:<math>\sigma^2(pK_{a2}) = \sigma^2(log \beta_{LH^+}) -2\sigma(log \beta_{LH^+},log \beta_{LH_2^{2+}}) \sigma(log \beta_{LH^+}) \sigma(log \beta_{LH_2^{2+}}) + \sigma^2(log \beta_{LH_2^{2+}}) </math>
où <math>\sigma(log \beta_{LH^+},log \beta_{LH_2^{2+}})</math> est le coefficient de corrélation entre <math>log \beta_{LH^+}</math> et <math>log \beta_{LH_2^{2+}}</math>. Les coefficients de corrélation entre constantes dérivées sont aussi des fonctions de celles entre les constantes de formation. Puisque l'erreur est positive mais que les coefficients de corrélation peuvent être négatifs, l'incertitude sur la valeur des constantes dérivées peut être soit plus grande ou plus petite que ce que les règles normales de la propagation d'erreur auraient prévues. Parce que les constantes de protonation <math>log \beta_{LH^+}</math> et <math>log \beta_{LH_2^{2+}}</math> sont probablement co-reliées négativement (un agrandissement de l'une entraînerait un amoindrissement compensatoire de l'autre pour rétablir un accord aux données), l'incertitude sur <math>pK_{a2}</math> sera probablement plus grande que celle anticipée par la propagation d'erreur normale.

Les constantes dérivées constituent une représentation équivalente d'un modèle chimique. Dans cet exemple, <math>pK_{a1}</math> et <math>pK_{a2}</math> peuvent entièrement et de façon entièrement équivalente remplacer <math>\beta_{LH^+}</math> et <math>\beta_{LH_2^{2+}}</math>, même si l'une ou l'autre de ces représentations est employée dans l'affinement du modèle parce qu'exigé par le logiciel ou par choix personnel, mais les rapports d'erreurs entre les paramètres (variance et covariance) varieront d'une représentation à l'autre, comme l'exemple ici le démontre.

Parfois même, un modèle construit d'équilibres de formation (avec constantes <math>\beta</math>) n'est pas le mieux adapté au système expérimental. Tout équilibre de formation présume que les concentrations des réactifs libres ne seront pas négligeables alors que, dans bien des cas, les constantes de formation sont tellement grandes qu'il ne reste presque plus de l'un ou d'un autre réactif en forme libre. Cela peut donner des difficultés pendant les calculs des concentrations, des valeurs de <math>\beta</math> très incertaines et un calcul de constantes dérivées qui met en œuvre des constantes <math>\beta</math> très incertaines<ref group="note">Si la concentration d'un réactif en état libre est très petite dans tous les échantillons (ou à tous les points d'une titration) à cause de très grandes constantes pour la formation des espèces complexes l'incorporant, le calcul des concentrations des espèces peut devenir numériquement problématique à cause du besoin d'invertir une matrice <math>\mathbf{D}</math> qui contiendra de très petits éléments. Le degré de difficulté dépendra de plusieurs facteurs : la précision des calculs à virgule flottante, les tailles des constantes de formation, les estimations de départ des concentrations à la première itération et des estimations de départ des valeurs des constantes de formation inconnues. L'affinement de constantes <math>\beta</math> inconnues qui dépendent de très petites concentrations de réactifs peut produire des valeurs hautement incertaines, puisque toute perturbation de la concentration déjà très petite d'un réactif libre sera très peu sentie dans les observables calculés (<math>y^{calc}</math>). Par exemple, une incertitude dans les mesures de pH de ±0.0005 se traduit par une incertitude d'environ ±10<sup>−10</sup> M en H<sup>+</sup> à pH 7 ou d'environ ±10<sup>−5</sup> M à pH 2, et donc une concentration d'un ion métallique tombant sous ces incertitudes ne perturbera pas une compétition entre métal et proton pour un même ligand qu'en deçà de l'erreur de la mesure, et sera donc essentiellement indécelable et sans conséquence pour le pH calculé. De tels situations peuvent survenir par exemple en présence de complexes ligand-métal très fortement liés, où il n'y aura jamais des quantités appréciables de métal libre. Finalement, une constante dérivée, telle que celle régissant un échange de ligands, pourrait être d'un plus grand intérêt que les constantes de formation, mais le calcul de constantes dérivées souffrira si elle met en œuvre de très grandes constantes hautement incertaines. Dans de tels situations, on peut reformuler le modèle pour ne jamais impliquer des réactifs libres à concentrations négligeables, ni de constantes de formation impliquant de tels réactifs libres, mais permettant le calcul direct et moins incertain des constantes dérivées. </ref>.

Potvin (1990b) a présenté une manière de construire des modèles équivalents, d'en déduire les rapports d'erreur et d'éviter de devoir composer avec des concentrations négligeables en réactifs libres.

== Logiciels ==

Un grand nombre de logiciels visant le calcul de constantes d'équilibre est paru dans la littérature scientifique, pas tous aussi utiles ou rigoureux<ref name="HQ">Gans, Sabatini et Vacca (1996) en font un survol et donnent une compilation, tout en vantant leur logiciel.</ref>.

Les logiciels les plus utilisés sont :
* données potentiométriques ou pH-métriques : Hyperquad<ref name="hyperquad" />, BEST (Martell et Motekaitis, 1992), PSEQUAD<ref name=Leggett>{{Ouvrage|langue=en|auteur1=David J. Leggett|responsabilité1=éditeur|titre=Computational methods for the determination of formation constants|éditeur=Plenum Press|lieu=New York|année=1985|pages totales=478|isbn=978-0-306-41957-7|oclc=12345160}}.</ref>
* données spectrophotométriques : Hyperquad, SQUAD<ref name="Leggett" />, Specfit<ref name="Specfit">H. Gampp, M. Maeder, C. J. Mayer et A. Zuberbühler, ''Talanta'' (1985), '''32''', 95-101, 257-264.</ref> (Specfit/32 est un produit commercial)
* données de RMN : HypNMR<ref>[http://www.hyperquad.co.uk/hypnmr.htm HypNMR]</ref>{{,}}<ref>[http://www.nuigalway.ie/chem/Mike/eqnmr.htm EQNMR]</ref>

On peut en principe faire les calculs nécessaires de manière dynamique à l'aide de logiciels à feuilles de calcul. Pour certains systèmes simples, il existe des feuilles de calcul pré-conçues pour ce faire<ref>{{Ouvrage|langue=en|auteur1=E. Joseph Billo|titre=Excel for chemists|sous-titre=a comprehensive guide|éditeur=John Wiley & Sons|lieu=Hoboken, N.J|année=2011|numéro d'édition=2|pages totales=732|isbn=978-1-118-09395-5|isbn2=978-1-118-09393-1|isbn3=978-1-118-09394-8|oclc=768243490|lire en ligne=http://www.worldcat.org/title/excel-for-chemists-a-comprehensive-guide/oclc/768243490/viewport}}</ref> mais leurs calculs ne suivent pas le cheminement exposé ici et utilisent le module boîte-noire SOLVER<ref> [http://www.solver.com/ SOLVER]</ref> pour réaliser les minimisations par la méthode des moindres carrés.

=== Particularités ===

Certains logiciels ont été écrits pour des ordinateurs depuis longtemps obsolètes. Parfois, ils auront été modernisés dans des mises en œuvre locales.

La plupart des logiciels suivent la [[Méthode des moindres carrés#Ajustement de modèles non linéaires|méthode Gauss-Newton]] décrite ici. En fait, l'approche numérique importe peu, pourvu que le minimum de la fonction objectif soit bel et bien atteint, puisque le même minimum devrait être atteint par toutes les approches à partir des mêmes données. Cependant, le minimum à atteindre et, donc, les résultats ultimes dépendent de la pondération utilisée, et les logiciels sont inégaux sur cet aspect. Aussi, le calcul correct des incertitudes sur les paramètres requiert la [[jacobienne]] (complète si on traite plus d'une sorte de données), mais dépend aussi de la pondération utilisée. Sur ces aspects, certaines particularités de ces logiciels sont à noter :

* BEST est conçu pour les titrations pH-métriques et utilise une pondération selon la pente locale de la courbe pH-volume. La recherche du minimum se fait heuristiquement, ce qui évite le calcul de dérivées mais qui nécessite beaucoup d'itérations, et peut être erroné. Aucune estimation des incertitudes n'est possible.

* Hyperquad peut traiter des données potentiométriques et spectrophotométriques en même temps, ce qui nécessite que l'on minimise une double somme des carrés, pratique douteuse qui mène à des résultats biaisés. Ceci nécessite aussi une jacobienne qui comprend des éléments mixtes aux tailles possiblement dissemblables, ce qui peut rendre la recherche du minimum problématique. C'est peut-être la raison pour laquelle ce logiciel utilise l'algorithme de Levenberg-Marquardt. Même si seulement une sorte de données est traitée, la pondération ne prend en compte que les erreurs probables en volume de titrant et en mesure, ce qui biaise aussi les résultats et les incertitudes. HypNMR, des mêmes auteurs, semble suivre cet exemple.

* Specfit utilise l'[[analyse en composantes principales]]<ref group="note">En anglais : principal component analysis.</ref> pour choisir les longueurs d'onde les plus déterminantes auxquelles modeler l'absorbance. Ce logiciel semble n'utiliser aucune pondération des données.

* HypNMR semble aussi ne prendre en compte que les erreurs probables en volume de titrant et en mesure pour pondérer, tout comme Hyperquad par les mêmes auteurs, ce qui biaise aussi les résultats et les incertitudes.

* EQNMR normalement n'utilise pas de pondération, et le détail du calcul des incertitudes n'est pas clarifié et provient apparemment d'un rapport technique et d'une publication inaccessibles. L'algorithme de l'affinement est décrit en termes généraux dans une publication de 1968<ref>Fletcher, J. E. ; Spector, A. A. « A procedure for computer analysis of data from macromolecule-ligand binding studies », ''Comp. Biomed. Res.'' (1968) '''2''', 164-175.</ref> et une autre de 1973<ref>Fletcher, J. E. ; Ashbrook, J. D. ; Spector A. A. « Computer Analysis of Drug-Protein Data » (1973), ''Ann. New York Acad. Sci.'' (1973) '''226''', 69–81.</ref> qui, elles aussi, font référence à des rapports techniques inaccessibles.

== Annexes ==

=== Notes ===

{{Références|groupe=note}}

=== Références ===

{{références}}

=== Bibliographie ===

{{Traduction/Référence|en|Determination of equilibrium constants|3=281469121}}

* Alcock, R. M., F. R. Hartley et D. E. Rogers (1978) : A Damped Non-linear Least-squares Computer Program (DALSFEK) for the Evaluation of Equilibrium Constants from Spectrophotometric and Potentiometric Data, ''J. Chem. Soc. Dalton Trans.'', 115–123.
* Gans, P., A. Sabatini et A. Vacca (1996) : Investigation of Equilibria in Solution. Determination of equilibrium constants with the Hyperquad suite of programs. ''Talanta'', '''43''', 1739–1753.
* {{Ouvrage|langue=en|prénom1=W. C.|nom1=Hamilton|titre=Statistics in Physical Science|éditeur=Ronald Press, New York|année=1964}}
* {{Ouvrage|langue=en|co-auteurs=R. J. Motekaitis|prénom1=A. E.|nom1=Martell|titre=The determination and use of stability constants|éditeur=Wiley-VCH|année=1992|isbn=}}
* Motekaitis, R. J. et A. E. Martell (1982) : BEST - a new program for rigourous calculation of equilibrium parameters of complex multicomponent systems, ''Can. J. Chem.'', '''60''', 2403–2409.
* {{Ouvrage|co-auteurs=W. Wasserman and M. H. Kutner|prénom1=J.|nom1=Neter|titre=Applied Linear Regression Models|éditeur=R. D. Irwin : Homewood, IL|année=1983|isbn=}}
* Potvin, P. G. (1990a) : Modelling complex solution equilibria. I. Fast, worry-free least-squares refinement of equilibrium constants, ''Can. J. Chem.'', '''68''', 2198–2207.
* Potvin, P. G. (1990b) : Modelling complex solution equilibria. II. Systems involving ligand substitutions and uncertainties in equilibrium constants derived from formation constants, ''Can. J. Chem.'', '''68''', 2208–2211.
* Potvin, P. G. (1994) : Modelling complex solution equilibria. III. Error-robust calculation of equilibrium constants from pH or potentiometric titration data, ''Anal. Chim. Acta'', '''299''', 43–57.

{{Palette|Constantes d'équilibre}}
{{Portail|chimie}}

{{DEFAULTSORT:Determination des constantes d'equilibre}}
[[Catégorie:Chimie des équilibres]]
[[Catégorie:Thermodynamique chimique]]